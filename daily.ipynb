{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def order_indices(list1, list2):\n",
    "    \"Return the order of elements of list2 in list1 assuming that list1 is a perturbation of list2\"\n",
    "    dict1 = dict()\n",
    "    for index, element in enumerate(list1):\n",
    "        dict1[element] = index\n",
    "    return [dict1[element] for element in list2]\n",
    "\n",
    "a = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "b = [1, 4, 2, 3, 8, 6, 5, 7]\n",
    "\n",
    "print(order_indices(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have an input that has m as parameter and NGA50 and misassemblies as output.\n",
    "# I want to visualize the output as a function of m.\n",
    "# first lits is m, second and third are NGA50 and misassemblies respectively.\n",
    "import matplotlib.pyplot as plt\n",
    "input = [[ 10, 50, 100, 200, 500, 1000, 2000, 2500, 3000, 3500], [967, 940, 905, 885, 867, 830, 744, 682, 560, 494], [8357, 8357, 8357, 8357, 8357, 8357, 9422, 9873, 12787, 14430]]\n",
    "\n",
    "# dot plot the input showing NGA50 and misassemblies on y and x axis respectively and use shades of green to show the values of m. also annotate m on each point.\n",
    "\n",
    "plt.scatter(input[1], input[2], c=input[0], cmap='Greens')\n",
    "plt.ylabel('NGA50 (Kb)')\n",
    "plt.xlabel('misassemblies')\n",
    "\n",
    "# annotate m on each point and make sure annotations are not overlapping\n",
    "for i, txt in enumerate(input[0]):\n",
    "    plt.annotate(txt, (input[1][i], input[2][i]))\n",
    "\n",
    "# add blue point as baseline with value 361 and 1396 for misassemblies and NGA50 respectively\n",
    "plt.scatter(361, 1396, c='blue')\n",
    "# show plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from adjustText import adjust_text\n",
    "\n",
    "input = [\n",
    "    [10, 50, 100, 200, 500, 1000, 2000, 2500, 3000, 3500, 3700, 4000],\n",
    "    [967, 940, 905, 885, 867, 830, 744, 682, 560, 494, 477, 503],\n",
    "    [8357, 8357, 8357, 8357, 8357, 8357, 9422, 9873, 12787, 14430, 14964, 10935]\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Dot plot the input, showing NGA50 and misassemblies on y and x axes respectively,\n",
    "# using shades of blue to represent the values of m.\n",
    "scatter = ax.scatter(input[1], input[2], c=input[0], cmap='Greens', edgecolors='black', s=100)\n",
    "\n",
    "# Add a red point as the baseline with values 361 and 1396 for misassemblies and NGA50 respectively.\n",
    "ax.scatter(361, 1396, c='red', edgecolors='black', s=100)\n",
    "ax.scatter(365, 16601, c='blue', edgecolors='black', s=100)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_ylabel('NGA50 (Mb)')\n",
    "ax.set_xlabel('Misassemblies')\n",
    "ax.set_title('Misassemblies vs. NGA50')\n",
    "\n",
    "# Add a grid\n",
    "ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Format y-axis labels in kilobytes\n",
    "formatter = FuncFormatter(lambda x, _: f'{int(x/1000)}')\n",
    "ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "# Annotate points without overlapping and adjust text position\n",
    "labels = [str(label) for label in input[0]]\n",
    "texts = [plt.annotate(label, (x, y), xytext=(5.3, 5.3), textcoords='offset points', ha='right', va='bottom', arrowprops=dict(arrowstyle='->', color='black')) for x, y, label in zip(input[1], input[2], labels)]\n",
    "adjust_text(texts)\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = fig.colorbar(scatter, ax=ax)\n",
    "cbar.set_label('m')\n",
    "\n",
    "# Adjust spacing and display the plot\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from adjustText import adjust_text\n",
    "\n",
    "input = [\n",
    "    [10, 50, 100, 200, 500, 1000, 2000, 2500, 3000, 3500, 3700, 4000],\n",
    "    [967, 940, 905, 885, 867, 830, 744, 682, 560, 494, 477, 503],\n",
    "    [8357, 8357, 8357, 8357, 8357, 8357, 9422, 9873, 12787, 14430, 14964, 10935]\n",
    "]\n",
    "# input85 = [\n",
    "#     [5000, 10000, 15000, 20000, 75000],\n",
    "#     [525, 467, 452, 449, 434],\n",
    "#     [13949, 16162, 16383, 17256, 17256]    \n",
    "# ]\n",
    "# input80 = [\n",
    "#     [5000, 10000, 15000, 20000, 75000],\n",
    "#     [559, 473, 451, 449, 430],\n",
    "#     [12147, 16162, 17256, 17256, 17256]\n",
    "# ]\n",
    "\n",
    "\n",
    "input85 = [\n",
    "    [75000],\n",
    "    [434],\n",
    "    [17256]    \n",
    "]\n",
    "input80 = [\n",
    "    [ 75000],\n",
    "    [ 430],\n",
    "    [ 17256]\n",
    "]\n",
    "    \n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Dot plot the input, showing NGA50 and misassemblies on y and x axes respectively,\n",
    "# using shades of blue to represent the values of m.\n",
    "# input in blacks, shape: circle\n",
    "ax.scatter(input[1], input[2], c=input[0], cmap='Greens', edgecolors='black', s=100, marker=\"o\")\n",
    "# input85 in blues and squares\n",
    "#ax.scatter(input85[1], input85[2],  c='green', edgecolors='black', s=100, marker=\"s\")\n",
    "# input80 in greens\n",
    "ax.scatter(input80[1], input80[2],  c='magenta', edgecolors='black', s=100, marker=\"d\")\n",
    "\n",
    "# Add a red point as the baseline with values 361 and 1396 for misassemblies and NGA50 respectively.\n",
    "ax.scatter(361, 1396, c='red', edgecolors='black', s=100)\n",
    "ax.scatter(365, 16601, c='blue', edgecolors='black', s=100)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_ylabel('NGA50 (Mb)')\n",
    "ax.set_xlabel('Misassemblies')\n",
    "ax.set_title('Misassemblies vs. NGA50')\n",
    "\n",
    "# Add a grid\n",
    "ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Format y-axis labels in kilobytes\n",
    "formatter = FuncFormatter(lambda x, _: f'{int(x/1000)}')\n",
    "ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "# Annotate points without overlapping and adjust text position\n",
    "# labels = [str(label) for label in input[0]]\n",
    "# texts = [plt.annotate(label, (x, y), xytext=(5.3, 5.3), textcoords='offset points', ha='right', va='bottom', arrowprops=dict(arrowstyle='->', color='black')) for x, y, label in zip(input[1], input[2], labels)]\n",
    "# adjust_text(texts)\n",
    "\n",
    "# annotate input85\n",
    "# labels85 = [str(label) for label in input85[0]]\n",
    "# texts85 = [plt.annotate(label, (x, y), xytext=(5.3, 5.3), textcoords='offset points', ha='right', va='bottom', arrowprops=dict(arrowstyle='->', color='black')) for x, y, label in zip(input85[1], input85[2], labels85)]\n",
    "# adjust_text(texts85)\n",
    "\n",
    "# annotate input80\n",
    "# labels80 = [str(label) for label in input80[0]]\n",
    "# texts80 = [plt.annotate(label, (x, y), xytext=(5.3, 5.3), textcoords='offset points', ha='right', va='bottom', arrowprops=dict(arrowstyle='->', color='black')) for x, y, label in zip(input80[1], input80[2], labels80)]\n",
    "# adjust_text(texts80)\n",
    "\n",
    "ax.set_ylim(8000,18000)\n",
    "ax.set_xlim(300,900)\n",
    "# Add a colorbar\n",
    "cbar = fig.colorbar(scatter, ax=ax)\n",
    "cbar.set_label('m')\n",
    "\n",
    "\n",
    "\n",
    "# Adjust spacing and display the plot\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot goldrush and goldrush_physlr on the same plot with first value as y and second as x\n",
    "# plot goldrush as blue and goldrush_physlr as green\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from adjustText import adjust_text\n",
    "\n",
    "\n",
    "goldrush = [16601382,\t365]\n",
    "goldrush_physlr = [17721256, 429]\n",
    "\n",
    "plt.scatter(goldrush[1], goldrush[0], c='blue', s=100)\n",
    "plt.scatter(goldrush_physlr[1], goldrush_physlr[0], c='green', s=100)\n",
    "\n",
    "# divide y labels by 1000000 to get in Mb\n",
    "formatter = FuncFormatter(lambda x, _: f'{(x/1000000)}')\n",
    "plt.gca().yaxis.set_major_formatter(formatter)\n",
    "\n",
    "# xlimit = [ 350 - 450]\n",
    "plt.xlim(300, 500)\n",
    "plt.ylim(16000000, 18000000)\n",
    "plt.legend(['GoldRush', 'GoldRush+Physlr'], loc='upper left')\n",
    "plt.xlabel('misassemblies')\n",
    "plt.ylabel('NGA50 (Mb)')\n",
    "plt.title('GoldRush before/after Physlr. Misassemblies vs. NGA50')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Assuming `indices_ordered` is your list of values\n",
    "# indices_ordered = [ 2, 7, 6, 8, 10, 12, 13, 14]\n",
    "# indices_ordered = [ 10, 8 , 9 , 7 , 5 , 6 , 3 , 2 , 1]\n",
    "\n",
    "indices_ordered = [ 10, 8 , 9 , 7 , 5 , 6 , 3 , 2 , 1]\n",
    "#indices_ordered = [ 0, 8 , 9 , 7 , 5 , 6 , 3 , 2 , 1]\n",
    "# indices_ordered = random.sample(range(1, 100), 40)\n",
    "# indices_ordered = list(range(1, 100+1))\n",
    "\n",
    "\n",
    "\n",
    "# Enumerate the indices_ordered list\n",
    "\n",
    "indices = list(range(len(indices_ordered)))\n",
    "\n",
    "# Create a Linear Regression model and fit it to the data\n",
    "lr_model = \"ransac\"\n",
    "if model == \"linear\":\n",
    "    model = LinearRegression()\n",
    "    coef = model.coef_\n",
    "elif model == \"ransac\":\n",
    "    RANSACRegressor(base_estimator=LinearRegression(), min_samples=0.85)\n",
    "    coef = model.estimator_.coef_  \n",
    "\n",
    "input = [[i] for i in indices]\n",
    "model.fit(input, indices_ordered)\n",
    "y_pred = model.predict(input)\n",
    "\n",
    "\n",
    "loss_mse = ((indices_ordered - y_pred) ** 2).mean() \n",
    "epsilon = 1e-10\n",
    "y = [ y + epsilon for y in indices_ordered]\n",
    "loss_mape = np.mean(np.abs((np.array(indices_ordered) - y_pred) / y)) * 100\n",
    "loss_r2 = 1 - model.score(input, indices_ordered)\n",
    "\n",
    "\n",
    "\n",
    "print(np.array(indices_ordered))\n",
    "print(type(np.array(indices_ordered)))\n",
    "print(y_pred)\n",
    "print(type(y_pred))\n",
    "print((np.array(indices_ordered) - y_pred))\n",
    "\n",
    "\n",
    "print(\"losse mse: \", loss_mse)\n",
    "print(\"loss mape: \", loss_mape)\n",
    "print(\"loss r2: \", loss_r2)\n",
    "print(\"coef: \", coef)\n",
    "\n",
    "\n",
    "print(1-1.)\n",
    "# Plot the data points and the fitted model\n",
    "plt.scatter(input, y, color='blue', label='Data Points')\n",
    "plt.plot(input, y_pred, color='red', label='Linear Regression Model')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Linear Regression')\n",
    "plt.legend()\n",
    "plt.show()\n",
    " \n",
    " \n",
    " \n",
    "a = np.array([1, 2, 3, 4, 5])\n",
    "b = np.array([1., 2., 3., 4., 5.])\n",
    "\n",
    "print (a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Assuming `indices_ordered` is your list of values\n",
    "indices_ordered = [2, 7, 6, 8, 10]\n",
    "\n",
    "# Enumerate the indices_ordered list\n",
    "x = list(range(len(indices_ordered)))\n",
    "y = indices_ordered\n",
    "\n",
    "# Define the segment breakpoints\n",
    "breakpoints = [2]\n",
    "\n",
    "# Split the data into segments\n",
    "segments_x = np.split(x, np.where(np.diff(x) > breakpoints[0])[0] + 1)\n",
    "segments_y = np.split(y, np.where(np.diff(x) > breakpoints[0])[0] + 1)\n",
    "\n",
    "# Create an empty list to store the predicted values\n",
    "y_pred = []\n",
    "\n",
    "# Fit linear regression to each segment and make predictions\n",
    "for segment_x, segment_y in zip(segments_x, segments_y):\n",
    "    model = LinearRegression()\n",
    "    model.fit([[i] for i in segment_x], segment_y)\n",
    "    segment_y_pred = model.predict([[i] for i in segment_x])\n",
    "    y_pred.extend(segment_y_pred)\n",
    "\n",
    "# Plot the data points and the piecewise linear regression model\n",
    "plt.scatter(x, y, color='blue', label='Data Points')\n",
    "plt.plot(x, y_pred, color='red', label='Piecewise Linear Regression Model')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Piecewise Linear Regression')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Assuming `x` and `y` are your data points\n",
    "x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "y = np.array([2, 4, 5, 7, 8, 10, 12, 14, 16, 18])\n",
    "\n",
    "# Define the segment breakpoints\n",
    "breakpoints = [4]\n",
    "\n",
    "# Fit piecewise linear regression\n",
    "X = np.column_stack([x, np.where(x <= breakpoints[0], 0, 1)])\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "# Get the fitted parameters\n",
    "intercept, slope1, slope2 = result.params\n",
    "\n",
    "# Generate the predicted values for the segments\n",
    "y_pred_1 = intercept + slope1 * x[x <= breakpoints[0]]\n",
    "y_pred_2 = intercept + slope2 * x[x > breakpoints[0]]\n",
    "\n",
    "# Plot the data and piecewise linear regression model\n",
    "plt.scatter(x, y, color='blue', label='Data Points')\n",
    "plt.plot(x[x <= breakpoints[0]], y_pred_1, color='red', label='Segment 1')\n",
    "plt.plot(x[x > breakpoints[0]], y_pred_2, color='green', label='Segment 2')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Piecewise Linear Regression')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from collections import Counter\n",
    "n = 3000000\n",
    "# make a list of x from 1 to n\n",
    "indices_ordered = list(range(1, n+1))\n",
    "# randomly perturbe the x values\n",
    "random.shuffle(indices_ordered)\n",
    "\n",
    "\n",
    "len_diff = len(indices_ordered) - 1\n",
    "# diff of consecutive elements; orientation: consistent with most zeros\n",
    "diff1 = [abs(y-x-1) for x, y in zip(indices_ordered, indices_ordered[1:])]\n",
    "diff2 = [abs(x-y-1) for x, y in zip(indices_ordered, indices_ordered[1:])]  \n",
    "diff1_zeros = diff2.count(0)\n",
    "diff2_zeros = diff2.count(0)\n",
    "if diff1_zeros > diff2_zeros:\n",
    "    diff = diff1\n",
    "    orientation = \"+\"\n",
    "else: \n",
    "    diff = diff2\n",
    "    orientation = \"-\"\n",
    "if max(diff1_zeros, diff2_zeros) < len_diff/2:\n",
    "    orientation = \".\"\n",
    "\n",
    "unique_counts = Counter(diff)\n",
    "entropy = -1 * sum([count/len_diff * math.log2(count/len_diff)\n",
    "                    for num, count in unique_counts.items()])\n",
    "\n",
    "print(entropy, orientation)\n",
    "#print(diff)\n",
    "\n",
    "\n",
    "indices_ordered = list(range(1, n+1))\n",
    "# randomly shuffle only 10% of the indices_ordered values\n",
    "n = len(indices_ordered)\n",
    "shuffle_count = int(n * 0.1)\n",
    "shuffled_indices = random.sample(indices_ordered, shuffle_count)\n",
    "random.shuffle(shuffled_indices)\n",
    "shuffled_list = indices_ordered[:]\n",
    "shuffled_list[:shuffle_count] = shuffled_indices\n",
    "indices_ordered = shuffled_list\n",
    "\n",
    "len_diff = len(indices_ordered) - 1\n",
    "# diff of consecutive elements; orientation: consistent with most zeros\n",
    "diff1 = [abs(y-x-1) for x, y in zip(indices_ordered, indices_ordered[1:])]\n",
    "diff2 = [abs(x-y-1) for x, y in zip(indices_ordered, indices_ordered[1:])]  \n",
    "diff1_zeros = diff1.count(0)\n",
    "diff2_zeros = diff2.count(0)\n",
    "if diff1_zeros > diff2_zeros:\n",
    "    diff = diff1\n",
    "    orientation = \"+\"\n",
    "else: \n",
    "    diff = diff2\n",
    "    orientation = \"-\"\n",
    "if max(diff1_zeros, diff2_zeros) < len_diff/2:\n",
    "    orientation = \".\"\n",
    "\n",
    "unique_counts = Counter(diff)\n",
    "entropy = -1 * sum([count/len_diff * math.log2(count/len_diff)\n",
    "                    for num, count in unique_counts.items()])\n",
    "\n",
    "print(entropy, orientation)\n",
    "#print(indices_ordered)\n",
    "#print(diff)\n",
    "#print(diff1)\n",
    "print(diff1.count(0))\n",
    "#print(diff2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(1, 31))\n",
    "for index, value in enumerate(x):\n",
    "    print(index, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Assuming `indices_ordered` is your list of values\n",
    "# indices_ordered = [ 2, 7, 6, 8, 10, 12, 13, 14]\n",
    "# indices_ordered = [ 10, 8 , 9 , 7 , 5 , 6 , 3 , 2 , 1]\n",
    "def longest_increasing_subarray(arr):\n",
    "    n = len(arr)\n",
    "    tail_values = [float('inf')] * n\n",
    "    prev_indices = [-1] * n\n",
    "    tail_indices = [0] * n\n",
    "    length = 1\n",
    "\n",
    "    for i in range(0, n):\n",
    "        if arr[i] < tail_values[0]:\n",
    "            tail_values[0] = arr[i]\n",
    "            tail_indices[0] = i\n",
    "        elif arr[i] >= tail_values[length - 1]:\n",
    "            tail_values[length] = arr[i]\n",
    "            prev_indices[i] = tail_indices[length - 1]\n",
    "            tail_indices[length] = i\n",
    "            length += 1\n",
    "        else:\n",
    "            left, right = 0, length - 1\n",
    "            while left < right:\n",
    "                mid = (left + right) // 2\n",
    "                if arr[i] >= tail_values[mid]:\n",
    "                    left = mid + 1\n",
    "                else:\n",
    "                    right = mid\n",
    "\n",
    "            tail_values[left] = arr[i]\n",
    "            prev_indices[i] = tail_indices[left - 1]\n",
    "            tail_indices[left] = i\n",
    "\n",
    "    lis = []\n",
    "    current_index = tail_indices[length - 1]\n",
    "    while current_index >= 0:\n",
    "        lis.append(arr[current_index])\n",
    "        current_index = prev_indices[current_index]\n",
    "\n",
    "    lis.reverse()\n",
    "\n",
    "    return lis\n",
    "\n",
    "def orient_eval_order(indices_ordered, technique = 1, lr_model = \"linear\"):\n",
    "    \"\"\"\n",
    "    Given a perturbation of 1:n, determine the orientation and evaluate the orderness of indices\n",
    "    using various techniques such as entropy, linear regression, etc.\n",
    "    \"\"\"\n",
    "\n",
    "    # Technique 1: Relative Entropy\n",
    "    if technique == 1:\n",
    "        # diff of consecutive elements; orientation: consistent with most zeros\n",
    "        len_diff = len(indices_ordered) - 1\n",
    "        diff = [y-x for x, y in zip(indices_ordered, indices_ordered[1:])] \n",
    "        len_pos = len([x for x in diff if x > 0])\n",
    "        # orientation: consistent with most ascesning/descending\n",
    "        if len_pos > 0.7 * len_diff:\n",
    "            orientation = \"+\"\n",
    "        elif len_pos < 0.3 * len_diff:\n",
    "            orientation = \"-\"\n",
    "        else:\n",
    "            orientation = \".\"\n",
    "\n",
    "        unique_counts = Counter(diff)\n",
    "        # calculate entropy on unique_counts\n",
    "        entropy = -1 * sum([count/len_diff * math.log2(count/len_diff)\n",
    "                            for num, count in unique_counts.items()])\n",
    "        normalized_entropy = entropy/math.log2(len_diff)\n",
    "        # print(\"|>>\", entropy, orientation, max(diff1_zeros, diff2_zeros), len_diff, file=sys.stderr, sep=\" \")\n",
    "        # print(\"|>>>\", indices_ordered, file=sys.stderr, sep=\" \")\n",
    "        return normalized_entropy, orientation\n",
    "\n",
    "    # Technique 2: Mean squared error (MSE)\n",
    "    if technique == 2:\n",
    "        len_list = len(indices_ordered)\n",
    "        mse_reg = sum([((element-(index))**2)/2\n",
    "                        for index, element in enumerate(indices_ordered)])/len_list\n",
    "        mse_rev = sum([((element-(len_list-index-1))**2)/2\n",
    "                        for index, element in enumerate(indices_ordered)])/len_list\n",
    "        if mse_reg < mse_rev:\n",
    "            orientation = \"+\"\n",
    "            mse = mse_reg\n",
    "        else:\n",
    "            orientation = \"-\"\n",
    "            mse = mse_rev\n",
    "        return mse, orientation\n",
    "\n",
    "    # Technique 3.1: Linear regression (Ransac available too, 15% outlier allowed)\n",
    "    # fit a linear regression model to the x, y for x, y in enumerate(indices_ordered)\n",
    "    # input = [[index, element] for index, element in enumerate(indices_ordered)]\n",
    "    # fir a linear regression model to input\n",
    "    if technique == 3:\n",
    "        if lr_model == \"linear\":\n",
    "            model = LinearRegression()\n",
    "        elif lr_model == \"ransac\":\n",
    "            model = RANSACRegressor(base_estimator=LinearRegression(), min_samples=0.85)\n",
    "        indices = list(range(len(indices_ordered)))\n",
    "        input = [[i] for i in indices]\n",
    "        model.fit(input, indices_ordered)\n",
    "        y_pred = model.predict(input)\n",
    "        loss_r2 = 1 - model.score(input, indices_ordered)\n",
    "        #loss_mse = ((indices_ordered - y_pred) ** 2).mean() / len(indices_ordered)\n",
    "        #epsilon = 1e-10\n",
    "        #y = np.array([ y + epsilon for y in indices_ordered])\n",
    "        #loss_mape = np.mean(np.abs((y - y_pred) / (y))) * 100\n",
    "\n",
    "        if lr_model == \"linear\":\n",
    "            coef = model.coef_\n",
    "        elif lr_model == \"ransac\":\n",
    "            coef = model.estimator_.coef_\n",
    "\n",
    "        if coef > 0.8 and coef < 1.2:\n",
    "            orientation = \"+\"\n",
    "        elif coef < -0.8 and coef > -1.2:\n",
    "            orientation = \"-\"\n",
    "        else:\n",
    "            orientation = \".\"\n",
    "        return loss_r2, orientation\n",
    "    \n",
    "    if technique == 7:\n",
    "        regular = longest_increasing_subarray(indices_ordered)\n",
    "        reverse = longest_increasing_subarray(indices_ordered[::-1])\n",
    "        if len(regular) > len(reverse):\n",
    "            orientation = \"+\"\n",
    "            lis = regular\n",
    "        else:\n",
    "            orientation = \"-\"\n",
    "            lis = reverse\n",
    "        score = (len(lis)*100)/len(indices_ordered)\n",
    "        if score < 50:\n",
    "            orientation = \".\"\n",
    "        print(\">>>\", lis, sep=\" \")\n",
    "        print(\">>>\", indices_ordered, sep=\" \")\n",
    "        print(\"(len(lis)*100)/len(indices_ordered)\")\n",
    "        return score, orientation\n",
    "\n",
    "def swap_elements(lst, percentage):\n",
    "    num_elements = len(lst)\n",
    "    num_swaps = int(num_elements * percentage / 100)\n",
    "\n",
    "    for _ in range(num_swaps):\n",
    "        # Select random indices for swapping\n",
    "        index1 = random.randint(0, num_elements - 1)\n",
    "        index2 = random.randint(0, num_elements - 1)\n",
    "\n",
    "        # Swap the elements at the selected indices\n",
    "        lst[index1], lst[index2] = lst[index2], lst[index1]\n",
    "\n",
    "    return lst\n",
    "\n",
    "def generate_list(n, p):\n",
    "    my_list = [1]  # Start with 1 as the first element\n",
    "    \n",
    "    for i in range(1, n):\n",
    "        if random.random() < p:\n",
    "            my_list.append(my_list[i-1] + 1)\n",
    "        else:\n",
    "            my_list.append(my_list[i-1] + 2)\n",
    "    \n",
    "    return my_list\n",
    "\n",
    "\n",
    "### INPUT:\n",
    "# indices_ordered = [ 10, 8 , 9 , 7 , 5 , 6 , 3 , 2 , 11]\n",
    "indices_ordered = [ 0, 8 , 9 , 7 , 5 , 6 , 3 , 2 , 1, 10, 11]\n",
    "# indices_ordered = random.sample(range(1, 100), 40)\n",
    "# indices_ordered = list(range(1, 100+1))\n",
    "\n",
    "#indices_ordered = generate_list(40, 0.7)\n",
    "\n",
    "# indices_ordered = list(range(1, 100+1))\n",
    "# indices_ordered = swap_elements(indices_ordered, 5)\n",
    "\n",
    "print(\"indices_ordered: \", indices_ordered, sep=\" \")\n",
    "print(\"indices_ordered reversed: \", indices_ordered[::-1])\n",
    "\n",
    "### CALL:\n",
    "score, orient = orient_eval_order(indices_ordered, technique = 7, lr_model = \"ransac\")\n",
    "\n",
    "### PLOTS:\n",
    "print(\"score: \", score)\n",
    "print(\"orientation: \", orient)\n",
    "if orient == \"+\":\n",
    "    # plot a y=x line\n",
    "    plt.plot(indices_ordered, indices_ordered, color='red', label='y=x')\n",
    "elif orient == \"-\":\n",
    "    # plot a y=-x line\n",
    "    plt.plot(indices_ordered, [-x+max(indices_ordered) for x in indices_ordered], color='red', label='y=-x')\n",
    "elif orient == \".\":\n",
    "    # plot a lin y = max(indices_ordered) /2 line\n",
    "    plt.plot(indices_ordered, [max(indices_ordered)/2 for x in indices_ordered], color='red', label='y=max/2')    \n",
    "\n",
    "scatter_x = np.array(list(range(len(indices_ordered))))\n",
    "plt.scatter(scatter_x, indices_ordered, color='blue', label='Data Points')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('data points')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"longest_increasing_subarray: \")\n",
    "print(longest_increasing_subarray(indices_ordered))\n",
    "print(longest_increasing_subarray(indices_ordered[::-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Data\n",
    "data = [\n",
    "    [\"dataset\", \"number of reads\", \"fold coverage\", \"NG50\", \"NGA50\", \"Number of misassemblies\", \"Number of local misassemblies\", \"Genome fraction (%)\", \"Duplication ratio\", \"Total length\", \"c Unaligned length\", \"c unaligned contigs\", \"color\", \"shape\"],\n",
    "    [\"Default\", \"14.7 M\", \"66.13 x\", \"25,588,817\", \"13,999,868\", \"738\", \"10,286\", \"90.283\", \"1.084\", \"3,030,637,100\", \"40,498,409\", \"1,945 + 3,214 part\", \"k\", \"o\"],\n",
    "    [\"Physlr m75\", \"2.6 M\", \"41.59 x\", \"25,669,674\", \"14,379,193\", \"740\", \"6,935\", \"90.439\", \"1.064\", \"2,966,585,422\", \"27,118,154\", \"1,237 + 2,350 part\", \"c\", \"^\"],\n",
    "    [\"Physlr m75\", \"2.6 M\", \"42/66 x\", \"21,401,998\", \"14,787,938\", \"668\", \"7,308\", \"90.349\", \"1.074\", \"2,994,372,436\", \"31,026,718\", \"1,421 + 2,525 part\", \"c\", \",\"],\n",
    "    [\"Physlr m90\", \"1.7 M\", \"33.17 x\", \"28,031,598\", \"14,289,427\", \"762\", \"3,974\", \"90.525\", \"1.069\", \"2,973,046,273\", \"15,782,277\", \"649 + 1,592 part\", \"m\", \"^\"],\n",
    "    [\"Physlr m90\", \"1.7 M\", \"33.17 x\", \"26,337,053\", \"16,589,002\", \"691\", \"4,245\", \"90.512\", \"1.085\", \"3,017,064,888\", \"18,065,577\", \"767 + 1,645 part\", \"m\", \",\"]\n",
    "]\n",
    "\n",
    "# Extract relevant columns\n",
    "headers = data[0]\n",
    "NGA50 = [int(row[4].replace(\",\", \"\")) for row in data[1:]]\n",
    "misa = [int(row[5].replace(\",\", \"\")) for row in data[1:]]\n",
    "local_misa = [int(row[6].replace(\",\", \"\")) for row in data[1:]]\n",
    "colors = [row[12] for row in data[1:]]\n",
    "shapes = [row[13] for row in data[1:]]\n",
    "\n",
    "# Create the first plot: misa against NGA50\n",
    "plt.subplot(2, 1, 1)\n",
    "for i in range(len(NGA50)):\n",
    "    plt.scatter(misa[i], NGA50[i] / 1000000, c=colors[i], marker=shapes[i], s=80)\n",
    "\n",
    "plt.xlabel(headers[5], fontsize=14)  # misa\n",
    "plt.ylabel(headers[4]+\" (Mb)\", fontsize=14)  # NGA50\n",
    "plt.xlim(650, 800)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "\n",
    "# Create the second plot: local misa against NGA50\n",
    "plt.subplot(2, 1, 2)\n",
    "for i in range(len(NGA50)):\n",
    "    plt.scatter(local_misa[i], NGA50[i] / 1000000, c=colors[i], marker=shapes[i], s=80)\n",
    "\n",
    "plt.xlabel(headers[6], fontsize=14)  # local misa\n",
    "plt.ylabel(headers[4]+\" (Mb)\", fontsize=14)  # NGA50\n",
    "plt.xlim(2000, 12000)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "\n",
    "# Adjust spacing between plots\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "plt.gcf().set_size_inches(6, 12)\n",
    "\n",
    "\n",
    "# Show the combined plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "c = [11, 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19]\n",
    "b = []\n",
    "b.append(a)\n",
    "b.append(c)\n",
    "print(b)\n",
    "print(b[1][3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a table from /projects/btl_scratch/aafshinfard/projects/physlr2/experiments/chm13_guppy_v5/rle_data/split_physlr_m75_rle_normap_default2/data/reads.63X.rle.k40-w32.n100-5000.c2-x.physlr.overlap.m75.mol.backbone.map-split.goldrush-chm13.split-2mb.rle.n10.bed.BAK\n",
    "# then plot histogram of colummn 7\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "filename = \"/projects/btl_scratch/aafshinfard/projects/physlr2/experiments/chm13_guppy_v5/rle_data/split_physlr_m75_rle_normap_default2/data/reads.63X.rle.k40-w32.n100-5000.c2-x.physlr.overlap.m75.mol.backbone.map-split.goldrush-chm13.split-2mb.rle.n10.bed.BAK\"\n",
    "df = pd.read_csv(filename, sep=\"\\t\", header=None)\n",
    "\n",
    "column_7 = df[6]\n",
    "column_9 = df[8]\n",
    "column_10 = df[9]\n",
    "\n",
    "plt.hist(column_7, bins=20)\n",
    "\n",
    "plt.xlabel(\"Column 7 - New score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Column 7 - New score\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# now plot column 7 against column 5 in a scatter plot \n",
    "column_5 = df[4]\n",
    "\n",
    "\n",
    "plt.scatter(column_7, column_5, s=0.1, c='r', marker=\"o\")\n",
    "plt.xlabel(\"New score\")\n",
    "plt.ylabel(\"Old score\")\n",
    "plt.title(\"New vs. old score\")\n",
    "\n",
    "\n",
    "plt.axvline(x=100, color='k', linestyle='--')\n",
    "plt.axhline(y=5000, color='k', linestyle='--')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# now plot column 7 against column 5 in not a scatter plot but in a density plot\n",
    "\n",
    "\n",
    "plt.hist2d(column_7, column_5, bins=20)\n",
    "plt.xlabel(\"New score\")\n",
    "plt.ylabel(\"Old score\")\n",
    "plt.title(\"New vs. old score density plot\")\n",
    "\n",
    "plt.axvline(x=85, color='k', linestyle='--')\n",
    "plt.axhline(y=3000, color='k', linestyle='--')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(column_9, column_10, s=0.1, c='r', marker=\"o\")\n",
    "plt.xlabel(\"len phys-map mxs\")\n",
    "plt.ylabel(\"len contig mxs\")\n",
    "plt.title(\"len phys-map mxs vs. len contig mxs density plot\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist2d(column_9, column_10, bins=20)\n",
    "plt.xlabel(\"len phys-map mxs\")\n",
    "plt.ylabel(\"len contig mxs\")\n",
    "plt.title(\"len phys-map mxs vs. len contig mxs density plot\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# \n",
    "\n",
    "plt.scatter(column_10, column_7, s=0.1, c='r', marker=\"o\")\n",
    "plt.xlabel(\"len contig mxs\")\n",
    "plt.ylabel(\"\")\n",
    "plt.title(\"len contig mxs vs scores\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist2d(column_10, column_7, bins=20)\n",
    "plt.xlabel(\"len contig mxs\")\n",
    "plt.ylabel(\"new score\")\n",
    "plt.title(\"len phys-map mxs vs. len contig mxs density plot\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist2d(column_9, column_7, bins=20)\n",
    "plt.xlabel(\"len contig mxs\")\n",
    "plt.ylabel(\"new score\")\n",
    "plt.title(\"len contig mxs density plot vs. new score\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# create a density plot using seaborn\n",
    "\n",
    "sns.kdeplot(column_7, column_5, shade=True, cmap=\"Reds\", shade_lowest=False)\n",
    "\n",
    "# Add a vertical line at x=100\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Column 7\")\n",
    "plt.ylabel(\"Column 5\")\n",
    "plt.title(\"Density Plot\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# then plot histogram of colummn 7\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "filename = \"/projects/btl_scratch/aafshinfard/projects/physlr2/experiments/chm13_guppy_v5/rle_data/default_physlr1_63X_fake_m75_normap/data/reads.63X.rle.k40-w32.n100-5000.c2-x.physlr.overlap.m75.mol.backbone.map-split.goldrush-chm13.rle.n10.bed.BAK\"\n",
    "df = pd.read_csv(filename, sep=\"\\t\", header=None)\n",
    "\n",
    "column_7 = df[6]\n",
    "column_9 = df[8]\n",
    "column_10 = df[9]\n",
    "\n",
    "plt.hist(column_7, bins=20)\n",
    "\n",
    "plt.xlabel(\"Column 7 - New score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Column 7 - New score\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# now plot column 7 against column 5 in a scatter plot \n",
    "column_5 = df[4]\n",
    "\n",
    "\n",
    "plt.scatter(column_7, column_5, s=0.1, c='r', marker=\"o\")\n",
    "plt.xlabel(\"New score\")\n",
    "plt.ylabel(\"Old score\")\n",
    "plt.title(\"New vs. old score\")\n",
    "\n",
    "\n",
    "plt.axvline(x=100, color='k', linestyle='--')\n",
    "plt.axhline(y=5000, color='k', linestyle='--')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# now plot column 7 against column 5 in not a scatter plot but in a density plot\n",
    "\n",
    "\n",
    "plt.hist2d(column_7, column_5, bins=20)\n",
    "plt.xlabel(\"New score\")\n",
    "plt.ylabel(\"Old score\")\n",
    "plt.title(\"New vs. old score density plot\")\n",
    "\n",
    "plt.axvline(x=85, color='k', linestyle='--')\n",
    "plt.axhline(y=3000, color='k', linestyle='--')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(column_9, column_10, s=0.1, c='r', marker=\"o\")\n",
    "plt.xlabel(\"len phys-map mxs\")\n",
    "plt.ylabel(\"len contig mxs\")\n",
    "plt.title(\"len phys-map mxs vs. len contig mxs density plot\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist2d(column_9, column_10, bins=20)\n",
    "plt.xlabel(\"len phys-map mxs\")\n",
    "plt.ylabel(\"len contig mxs\")\n",
    "plt.title(\"len phys-map mxs vs. len contig mxs density plot\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# \n",
    "\n",
    "plt.scatter(column_10, column_7, s=0.1, c='r', marker=\"o\")\n",
    "plt.xlabel(\"len contig mxs\")\n",
    "plt.ylabel(\"\")\n",
    "plt.title(\"len contig mxs vs scores\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist2d(column_10, column_7, bins=20)\n",
    "plt.xlabel(\"len phys-map mxs\")\n",
    "plt.ylabel(\"len contig mxs\")\n",
    "plt.title(\"len phys-map mxs vs. len contig mxs density plot\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# create a density plot using seaborn\n",
    "\n",
    "sns.kdeplot(column_7, column_5, shade=True, cmap=\"Reds\", shade_lowest=False)\n",
    "\n",
    "# Add a vertical line at x=100\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Column 7\")\n",
    "plt.ylabel(\"Column 5\")\n",
    "plt.title(\"Density Plot\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in a file and plot a histogram of column 1\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_add = \"/projects/btl_scratch/aafshinfard/projects/physlr2/experiments/chm13_guppy_v5/rle_data/default_physlr1_63X_fake_m10/data/reads.63X.rle.k40-w32.n100-5000.c2-x.physlr.overlap.m10.labeled.edge-weights\"\n",
    "\n",
    "# read the file\n",
    "df = pd.read_csv(file_add, sep=\"\\t\", header=None)\n",
    "\n",
    "# plot the histogram of column 1\n",
    "plt.hist(df[0], bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in a file and plot a histogram of column 1\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "main_file_add = \"/projects/btl_scratch/aafshinfard/projects/physlr2/experiments/chm13_guppy_v5/rle_data/default_physlr1_63X_fake_m10/data/reads.63X.rle.k40-w32.n100-5000.c2-x.physlr.overlap.m10.labeled.edge-weights\"\n",
    "\n",
    "\n",
    "#file_add = \"/projects/btl_scratch/aafshinfard/projects/physlr2/experiments/chm13_guppy_v5/rle_data/default_physlr1_63X_fake_m10/data/reads.63X.rle.k40-w32.n100-5000.c2-x.physlr.overlap.m10.labeled.edge-weights\"\n",
    "file_add = \"/projects/btl_scratch/aafshinfard/projects/physlr2/experiments/chm13_guppy_v5/rle_data/default_physlr1_63X_fake_m10_worstm10/data/reads.63X.rle.k40-w32.n100-5000.c2-x.physlr.overlap.m10.worst20.labeled.edge-weights\"\n",
    "\n",
    "# read the file\n",
    "main_df = pd.read_csv(main_file_add, sep=\"\\t\", header=None)\n",
    "df = pd.read_csv(file_add, sep=\"\\t\", header=None)\n",
    "\n",
    "# calculate the absolute values of column 1\n",
    "main_df_abs = main_df[0].abs()\n",
    "df_abs = df[0].abs()\n",
    "\n",
    "#threshold90 = main_df_abs.quantile(0.9)\n",
    "#threshold75 = main_df_abs.quantile(0.75)\n",
    "threshold90 = df_abs.quantile(0.9)\n",
    "threshold75 = df_abs.quantile(0.75)\n",
    "# cutoff at 400 absolute value\n",
    "# threshold400 = df_abs[df_abs > 400].count()[0]\n",
    "\n",
    "df_true = df[df[0] > 0]\n",
    "df_false = df[df[0] < 0] * -1\n",
    "\n",
    "plt.hist(df_true[0], bins=range(0, 4000, 10), alpha=0.6, color='green')\n",
    "plt.hist(df_false[0], bins=range(0, 4000, 10), alpha=0.6, color='red')\n",
    "\n",
    "# plot a vertical line at threshold90 and label it as m90\n",
    "plt.axvline(x=threshold90, color='b', linestyle='--')\n",
    "#plt.text(threshold90+10, 11000000, \"m90\", rotation=90, color='b')\n",
    "plt.text(threshold90+10, 4000000, \"m90\", rotation=90, color='b')\n",
    "\n",
    "plt.axvline(x=threshold75, color='b', linestyle='--')\n",
    "#plt.text(threshold75+10, 11000000, \"m75\", rotation=90, color='b')\n",
    "plt.text(threshold75+10, 4000000, \"m75\", rotation=90, color='b')\n",
    "# label x axis as edge weight\n",
    "plt.xlabel(\"Edge weight\")\n",
    "# title of the plot: Histogram of edge weights (True: green, False: red)\n",
    "plt.title(\"Histogram of edge weights (True: green, False: red)\")\n",
    "\n",
    "# limited the x axis to 2000\n",
    "plt.xlim(0, 1000)\n",
    "\n",
    "count_true_90 = df_true[df_true[0] >= threshold90].count()[0]\n",
    "count_true_75 = df_true[df_true[0] >= threshold75].count()[0]\n",
    "count_false_90 = df_false[df_false[0] >= threshold90].count()[0]\n",
    "count_false_75 = df_false[df_false[0] >= threshold75].count()[0]\n",
    "\n",
    "count_true_400 = df_true[df_true[0] >= 400].count()[0]\n",
    "count_false_400 = df_false[df_false[0] >= 400].count()[0]\n",
    "\n",
    "count_true_200 = df_true[df_true[0] >= 200].count()[0]\n",
    "count_false_200 = df_false[df_false[0] >= 200].count()[0]\n",
    "\n",
    "count_true_100 = df_true[df_true[0] >= 100].count()[0]\n",
    "count_false_100 = df_false[df_false[0] >= 100].count()[0]\n",
    "\n",
    "count_true_50 = df_true[df_true[0] >= 50].count()[0]\n",
    "count_false_50 = df_false[df_false[0] >= 50].count()[0]\n",
    "\n",
    "# percentage_false = df_true.count / df.count\n",
    "percentage_false = 100 * (df_false.count()[0] / df.count()[0])\n",
    "percentage_false_75 = 100 * (count_false_75 / (count_false_75 + count_true_75 ))\n",
    "percentage_false_90 = 100 * (count_false_90 / (count_false_90 + count_true_90 ))\n",
    "\n",
    "percentage_false_400 = 100 * (count_false_400 / (count_false_400 + count_true_400 ))\n",
    "percentage_false_200 = 100 * (count_false_200 / (count_false_200 + count_true_200 ))\n",
    "percentage_false_100 = 100 * (count_false_100 / (count_false_100 + count_true_100 ))\n",
    "percentage_false_50 = 100 * (count_false_50 / (count_false_50 + count_true_50 ))\n",
    "\n",
    "# store total number of reads in a variable\n",
    "total_edges = df.count()[0]\n",
    "# make a string our of total_reads that separates every 3 digits from right with a comma\n",
    "total_edges_str = \"{:,}\".format(total_edges)\n",
    "print(\"Total number of edges: \", total_edges_str)\n",
    "\n",
    "\n",
    "# print percentage of false edges with two decimal points\n",
    "print(\"percentage_false: \", round(percentage_false, 2))\n",
    "print(\"percentage_false m75: \", round(percentage_false_75, 2))\n",
    "print(\"percentage_false m90: \", round(percentage_false_90, 2))\n",
    "print(\"percentage_false 400: \", round(percentage_false_400, 2))\n",
    "print(\"percentage_false 200: \", round(percentage_false_200, 2))\n",
    "print(\"percentage_false 100: \", round(percentage_false_100, 2))\n",
    "print(\"percentage_false 50: \", round(percentage_false_50, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a file that on each line has the following fields: read1_name, read2_name, weight, and a list of comma separated indices\n",
    "# store it in a list of lists where each inner list has the following fields: read1_name, read2_name, weight, and a list of indices\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#file_add = \"reads.63X.rle.k40-w32.n100-5000.c2-x.physlr.overlap-pairs.false.shuf-n113600.tsv\"\n",
    "file_add = \"reads.63X.rle.k40-w32.n100-5000.c2-x.physlr.overlap-pairs.true.shuf-n886400.tsv\"\n",
    "add = \"/projects/btl_scratch/aafshinfard/projects/physlr2/experiments/chm13_guppy_v5/rle_data/default_physlr1_63X_fake_m10/data/\"\n",
    "\n",
    "skip_zero = False\n",
    "\n",
    "file_add = add + file_add\n",
    "print(file_add)\n",
    "list_of_lists = []\n",
    "with open(file_add) as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        line = line.split(\"\\t\")\n",
    "        line[2] = int(line[2])\n",
    "        # convert the last element of the list to a list of integers\n",
    "        if skip_zero:\n",
    "            line[-1] = [int(y) for y in line[-1].split(\",\") if int(y) != 0]\n",
    "        else:\n",
    "            #line[-1] = line[-1].split(\",\")\n",
    "            line[-1] = [int(y) for y in line[-1].split(\",\")]\n",
    "            #line[-1] = [x for x in line[-1].split(\",\")]\n",
    "        \n",
    "        list_of_lists.append(line)\n",
    "        \n",
    "\n",
    "# LIMITING THE SELECTION\n",
    "# pick only those with weight > 400, and pick theor absolute value\n",
    "#list_of_lists = [x for x in list_of_lists if abs(x[2]) > 10]\n",
    "list_of_lists = [x for x in list_of_lists if abs(x[2]) > 400]\n",
    "#list_of_lists = [x for x in list_of_lists if abs(x[2]) < 100]\n",
    "print(\"len(list_of_lists): \", len(list_of_lists))\n",
    "\n",
    "# RANDOM PICKING 9 LINES\n",
    "import random\n",
    "random_indices = random.sample(range(len(list_of_lists)), 9)\n",
    "random_lists = [list_of_lists[i] for i in random_indices]\n",
    "\n",
    "# now make 9 plots in a facet style. On each plot plot the line[-1] agains indices of the elements of line[-1]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 15), sharex=False, sharey=False)\n",
    "#fig, axs = plt.subplots(3, 3, figsize=(15, 15), sharex=True, sharey=True)\n",
    "max_len_y = 0\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        # x = random_lists[3*i+j][-1]\n",
    "        # plot a dot plot - y is the index of each element for x\n",
    "        y = random_lists[3*i+j][-1]\n",
    "        # print x\n",
    "        #y = list(range(len(random_lists[3*i+j][-1])))\n",
    "        x = list(range(len(y)))\n",
    "        print(\"read 1: \" + random_lists[3*i+j][0])\n",
    "        print(\"read 2: \" + random_lists[3*i+j][1])\n",
    "        print(\"x :\", x)\n",
    "        print(\"y :\", y)\n",
    "        \n",
    "        non_zero_y = [i for i in y if i != 0]\n",
    "        print(\"len non_zero_x: \", len(non_zero_y))\n",
    "        \n",
    "        # scatter plot \n",
    "        axs[i, j].plot(x, x, color='blue', label='y=x')\n",
    "        axs[i, j].scatter(x, y, s=0.3, c='r', marker=\"o\")\n",
    "        if (len(y)) > max_len_y:\n",
    "            max_len_y = len(y)\n",
    "        \n",
    "        \n",
    "        # annotate the plot with the read name and ratio of non-zero elements to total elements\n",
    "        axs[i, j].annotate( \"non-zero rate: \" + str(round(len(non_zero_y)/len(x), 5)) + \"\\n\" + random_lists[3*i+j][0] + \" vs \\n\" + random_lists[3*i+j][1] + \"\\nweight: \" + str(random_lists[3*i+j][2]), xy=(0.05, 0.95), xycoords='axes fraction')\n",
    "        #axs[i, j].set_ylim(0, 1000)\n",
    "        #axs[i, j].set_xlim(0, 1000)\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        axs[i,j].set_ylim(0, max_len_y * 1.1)\n",
    "        axs[i,j].set_xlim(0, max_len_y * 1.1)\n",
    "#axs[i, j].set_xticks([0, max_len_y])\n",
    "plt.show()\n",
    "# print random_lists\n",
    "for i in range(9):\n",
    "    print(random_lists[i][0], random_lists[i][1], random_lists[i][2])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def gather_data(full_file_ad):\n",
    "    x_values = []\n",
    "    y_values = [] \n",
    "    \n",
    "    with open(full_file_ad, 'r') as file:\n",
    "        line = file.readline().strip().split(' ')\n",
    "\n",
    "    # Extract the values\n",
    "    # read1_name, read2_name, edge_weight, *raw_mxs = line\n",
    "    if len(line) < 3:\n",
    "        return None, None\n",
    "    read1_name = line[0]\n",
    "    read2_name = line[1]\n",
    "    edge_weight = line[2]\n",
    "    raw_mxs = line[3:]\n",
    "    \n",
    "    # Process each element in raw_mxs\n",
    "    for element in raw_mxs:\n",
    "        #print(element)\n",
    "        x, y = element.split('_')\n",
    "        # remove any of the chars + - or : from x and y\n",
    "        x = x.replace('+', '')\n",
    "        x = x.replace('-', '')\n",
    "        x = x.replace(':', '')\n",
    "        y = y.replace('-', '')\n",
    "        y = y.replace('+', '')\n",
    "        y = y.replace(':', '')\n",
    "        x_values.append(int(x))\n",
    "        y_values.append(int(y))\n",
    "    \n",
    "    return x_values, y_values\n",
    "\n",
    "def get_limits(info_file_name):\n",
    "    # open the file and read the info from. The x limit is the second element, and the y limit is the 7th element in the line\n",
    "    with open(info_file_name, 'r') as file:\n",
    "        line = file.readline().strip()\n",
    "    # if size line < 7, then the file is empty\n",
    "    print(line)\n",
    "    line = line.split('\\t')\n",
    "    if len(line) < 7:\n",
    "        return None, None, None, None, None, None, None, None\n",
    "    x_name = line[0]\n",
    "    x_limit = int(line[1])\n",
    "    x_start = int(line[2])\n",
    "    x_finish = int(line[3])\n",
    "    orient = line[4]\n",
    "    y_name = line[5]\n",
    "    y_limit = int(line[6])\n",
    "    y_start = int(line[7])\n",
    "    y_finish = int(line[8])\n",
    "    \n",
    "    if orient == \"-\":\n",
    "        temp = x_start\n",
    "        x_start = x_finish\n",
    "        x_finish = temp\n",
    "    \n",
    "    return x_name, y_name, x_limit, y_limit, x_start, x_finish, y_start, y_finish\n",
    "\n",
    "file_ad = '/projects/btl_scratch/aafshinfard/projects/physlr2/experiments/datasets/aligned/pairs9'\n",
    "\n",
    "# plot a facet of 9 plots from 9 files\n",
    "figs, axs = plt.subplots(3, 3, figsize=(15, 15), sharex=False, sharey=False)\n",
    "\n",
    "for m in range(9):\n",
    "    file_name = 'false_pair_' + str(m+1) + '.verbose_mapping.tsv'\n",
    "    info_file_name = 'false_pair_' + str(m+1) + '.paf'\n",
    "    full_file_ad = file_ad + '/' + file_name\n",
    "    full_info_file_ad = file_ad + '/' + info_file_name\n",
    "    x_values, y_values = gather_data(full_file_ad)\n",
    "    x_name, y_name, x_limit, y_limit, x_start, x_finish, y_start, y_finish = get_limits(full_info_file_ad)\n",
    "    \n",
    "    # plot the m'th plot\n",
    "    i = int(m/3)\n",
    "    j = m%3\n",
    "    #draw a line from x_start, y_start to x_finish, y_finish\n",
    "    if x_start is not None:\n",
    "        # width of the line is 0.1\n",
    "        axs[i, j].plot([y_start, y_finish], [x_start, x_finish], color='red', label='ntLink', linewidth=0.5)\n",
    "    \n",
    "    axs[i, j].scatter(x_values, y_values, color='blue', label='y=x', s=0.1)\n",
    "    # limit x and y axis\n",
    "    if x_limit is not None:\n",
    "        print(\"i and j:\", i, j)\n",
    "        axs[i, j].set_xlim(0, y_limit)\n",
    "        axs[i, j].set_ylim(0, x_limit)\n",
    "        #annotate read names\n",
    "        axs[i, j].annotate( x_name + \" vs \\n \" + y_name, xy=(0.05, 0.95), xycoords='axes fraction')\n",
    "    \n",
    "    \n",
    "        \n",
    "    # annotate the plot with the read name\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Read a file of barcode to minimizer mapping that has one line per barcode and each line has the following format:\n",
    "# barcode_name  minimizer_1 minimizer_2 minimizer_3 ...\n",
    "# and store in an appropriate data structure\n",
    "\n",
    "file_ad = '/projects/btl_scratch/aafshinfard/projects/physlr2/experiments/datasets/aligned/pairs9/physlr_bxtomx_pair18'\n",
    "file_ad = '/projects/btl_scratch/aafshinfard/projects/physlr2/experiments/chm13_guppy_v5/rle_data/physlr_pair18_indexlr2/data'\n",
    "\n",
    "#file_name = 'reads.63X.rle.k40-w32.n100-5000.c2-x.physlr.true-false.pair18.true_pair1.tsv'\n",
    "#file_name = 'reads.63X.rle.k40-w32.n100-5000.c2-x.physlr.true-false.pair18.false_pair1.tsv'\n",
    "\n",
    "# file_name = 'pairs18.seqtk.k40-w32.n100-5000.c2-x.physlr.true_pair1.tsv'\n",
    "file_name = 'pairs18.seqtk.k40-w32.n100-5000.c2-x.physlr.false_pair4.tsv'\n",
    "\n",
    "file_full_ad = file_ad + '/' + file_name\n",
    "\n",
    "# initialize the data structure\n",
    "barcode_to_minimizer = {}\n",
    "\n",
    "# read the file\n",
    "with open(file_full_ad, 'r') as file:\n",
    "    line = file.readline().strip().split('\\t')\n",
    "    barcode_name = line[0]\n",
    "    minimizers = line[1].split(' ')\n",
    "    barcode_to_minimizer[barcode_name] = [int(x) for x in minimizers]\n",
    "    line = file.readline().strip().split('\\t')\n",
    "    barcode_name = line[0]\n",
    "    minimizers = line[1].split(' ')\n",
    "    barcode_to_minimizer[barcode_name] = [int(x) for x in minimizers]\n",
    "    \n",
    "# assuming the file had two lines of data.\n",
    "# iterate over the minimizers of the first line and for each minimizer, find the minimizer in the other line. report the index of the query and the index of the target minimizer.\n",
    "\n",
    "# print size of dictionary\n",
    "print(\"size of dictionary: \", len(barcode_to_minimizer))\n",
    "\n",
    "# print first item in the dictionary\n",
    "print(\"first item in the dictionary: \", list(barcode_to_minimizer.items())[0])\n",
    "\n",
    "# print second item in the dictionary\n",
    "print(\"second item in the dictionary: \", list(barcode_to_minimizer.items())[1])\n",
    "\n",
    "# grab the first item in the dictionary\n",
    "first = list(barcode_to_minimizer.items())[0]\n",
    "second = list(barcode_to_minimizer.items())[1]\n",
    "\n",
    "indices = []\n",
    "for element in first[1]:\n",
    "    # find the index of the element in the second list (may be absent)\n",
    "    index = second[1].index(element) if element in second[1] else -1\n",
    "    indices.append(index)\n",
    "\n",
    "# plot indices against 1:len(indices)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(len(indices))\n",
    "y = indices\n",
    "\n",
    "plt.scatter(x, y, s=0.1, c='r', marker=\"o\")\n",
    "\n",
    "plt.xlabel(\"Index of minimizer in first line\")\n",
    "\n",
    "plt.ylabel(\"Index of minimizer in second line\")\n",
    "\n",
    "plt.title(\"Index of minimizer in first line vs. Index of minimizer in second line\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Read a file of barcode to minimizer mapping that has one line per barcode and each line has the following format:\n",
    "# barcode_name  minimizer_1 minimizer_2 minimizer_3 ...\n",
    "# and store in an appropriate data structure\n",
    "\n",
    "file_ad = '/projects/btl_scratch/aafshinfard/projects/physlr2/experiments/datasets/aligned/pairs9/physlr_bxtomx_pair18'\n",
    "file_ad = '/projects/btl_scratch/aafshinfard/projects/physlr2/experiments/chm13_guppy_v5/rle_data/physlr_pair18_indexlr2/data'\n",
    "\n",
    "#file_name = 'reads.63X.rle.k40-w32.n100-5000.c2-x.physlr.true-false.pair18.true_pair1.tsv'\n",
    "#file_name = 'reads.63X.rle.k40-w32.n100-5000.c2-x.physlr.true-false.pair18.false_pair1.tsv'\n",
    "\n",
    "#file_name = 'pairs18.seqtk.k40-w32.n100-5000.c2-x.physlr.true_pair2.tsv'\n",
    "file_name = 'pairs18.seqtk.k40-w32.n100-5000.c2-x.physlr.false_pair1.tsv'\n",
    "\n",
    "file_full_ad = file_ad + '/' + file_name\n",
    "\n",
    "# initialize the data structure\n",
    "barcode_to_minimizer = {}\n",
    "barcode_to_minimizerloc = {}\n",
    "\n",
    "# read the file\n",
    "with open(file_full_ad, 'r') as file:\n",
    "    line = file.readline().strip().split('\\t')\n",
    "    barcode_name = line[0]\n",
    "    minimizers = line[1].split(' ')\n",
    "    # each minimizers is formatted like minhash:minloc, split them from : and store them in two lists minhash and minloc \n",
    "    minhash = []\n",
    "    minloc = []\n",
    "    for element in minimizers:\n",
    "        minhash.append(int(element.split(':')[0]))\n",
    "        minloc.append(int(element.split(':')[1]))\n",
    "    \n",
    "    barcode_to_minimizer[barcode_name] = [int(x) for x in minhash]\n",
    "    barcode_to_minimizerloc[barcode_name] = [int(x) for x in minloc]\n",
    "    \n",
    "    \n",
    "    \n",
    "    line = file.readline().strip().split('\\t')\n",
    "    barcode_name = line[0]\n",
    "    minimizers = line[1].split(' ')\n",
    "    minhash = []\n",
    "    minloc = []\n",
    "    for element in minimizers:\n",
    "        minhash.append(int(element.split(':')[0]))\n",
    "        minloc.append(int(element.split(':')[1]))\n",
    "    \n",
    "    barcode_to_minimizer[barcode_name] = [int(x) for x in minhash]\n",
    "    barcode_to_minimizerloc[barcode_name] = [int(x) for x in minloc]\n",
    "    \n",
    "# assuming the file had two lines of data.\n",
    "# iterate over the minimizers of the first line and for each minimizer, find the minimizer in the other line. report the index of the query and the index of the target minimizer.\n",
    "\n",
    "# print size of dictionary\n",
    "print(\"size of dictionary: \", len(barcode_to_minimizer))\n",
    "\n",
    "# print first item in the dictionary\n",
    "print(\"first item in the dictionary: \", list(barcode_to_minimizer.items())[0])\n",
    "\n",
    "# print second item in the dictionary\n",
    "print(\"second item in the dictionary: \", list(barcode_to_minimizer.items())[1])\n",
    "\n",
    "# grab the first item in the dictionary\n",
    "first = list(barcode_to_minimizer.items())[0]\n",
    "first_loc = list(barcode_to_minimizerloc.items())[0]\n",
    "second = list(barcode_to_minimizer.items())[1]\n",
    "second_loc = list(barcode_to_minimizerloc.items())[1]\n",
    "\n",
    "indices_first = []\n",
    "indices_second = []\n",
    "\n",
    "#for element and loc in first[1], first_loc[1]:\n",
    "for i in range(len(first[1])):\n",
    "    element = first[1][i]\n",
    "    loc = first_loc[1][i]\n",
    "    indices_first.append(loc)\n",
    "    # find the index of the element in the second list (may be absent)\n",
    "    index = second[1].index(element) if element in second[1] else 0\n",
    "    if index != 0:\n",
    "        indices_second.append(second_loc[1][index])\n",
    "    else:\n",
    "        indices_second.append(index)\n",
    "\n",
    "# plot indices against 1:len(indices)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = indices_first\n",
    "y = indices_second\n",
    "\n",
    "plt.scatter(x, y, s=0.1, c='r', marker=\"o\")\n",
    "\n",
    "plt.xlabel(\"Index of minimizer in first line\")\n",
    "\n",
    "plt.ylabel(\"Index of minimizer in second line\")\n",
    "\n",
    "plt.title(\".\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import t\n",
    "\n",
    "\n",
    "def make_LR_arrays(comm_mxs):\n",
    "    # given a dictionary of common minimizers, make two arrays of x and y values for each read\n",
    "    # arrays will be used for linear regression, so prepare numpy array format\n",
    "    x = []\n",
    "    y = []\n",
    "    for key in comm_mxs.keys():\n",
    "        x.append(comm_mxs[key][0])\n",
    "        y.append(comm_mxs[key][1])\n",
    "    \n",
    "    x = np.array(x).reshape((-1, 1))\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return x, y\n",
    "    \n",
    "\n",
    "def overlap_read_pairs(bxtomxs, bx1, bx2):\n",
    "    \"\"\"\n",
    "    Given a dictionary from barcode to minimizers, and two barcodes,\n",
    "    find the common minimizers between them (and their location on both reads), and also mismatch minimizers of each read (and their locations).\n",
    "    \"\"\"\n",
    "    mxs_1 = bxtomxs[bx1]\n",
    "    mxs_2 = bxtomxs[bx2]\n",
    "\n",
    "    # build a dict from mxs_2\n",
    "    mxs_2_dict = {}\n",
    "    for i in range(len(mxs_2)):\n",
    "        mxs_2_dict[mxs_2[i][1]] = mxs_2[i][0]\n",
    "\n",
    "    comm_mxs = {}\n",
    "    miss_1 = {}\n",
    "    miss_2 = {}\n",
    "    for i in range(len(mxs_1)):\n",
    "        if mxs_1[i][1] in mxs_2_dict:\n",
    "            comm_mxs[mxs_1[i][1]] = [mxs_1[i][0], mxs_2_dict[mxs_1[i][1]]]\n",
    "        else:\n",
    "            miss_1[mxs_1[i][1]] = mxs_1[i][0]\n",
    "    for key in mxs_2_dict.keys():\n",
    "        if key not in comm_mxs:\n",
    "            miss_2[key] = mxs_2_dict[key]\n",
    "    \n",
    "    return comm_mxs, miss_1, miss_2\n",
    "    \n",
    "\n",
    "def build_location_pairs(first, first_loc, second, second_loc):\n",
    "    indices_first = []\n",
    "    indices_second = []\n",
    "\n",
    "    #for element and loc in first[1], first_loc[1]:\n",
    "    for i in range(len(first[1])):\n",
    "        element = first[1][i]\n",
    "        loc = first_loc[1][i]\n",
    "        indices_first.append(loc)\n",
    "        # find the index of the element in the second list (may be absent)\n",
    "        index = second[1].index(element) if element in second[1] else 0\n",
    "        if index != 0:\n",
    "            indices_second.append(second_loc[1][index])\n",
    "        else:\n",
    "            indices_second.append(index)\n",
    "\n",
    "    return indices_first, indices_second\n",
    "\n",
    "\n",
    "\n",
    "# def linear_regression_full(x, y):\n",
    "#     # reshape x and y to be 2D arrays\n",
    "#     x = np.array(x).reshape((-1, 1))\n",
    "#     y = np.array(y)\n",
    "#     # create a model and fit it\n",
    "#     model = LinearRegression()\n",
    "#     model.fit(x, y)\n",
    "#     # get the coefficient of determination R^2\n",
    "#     r_sq = model.score(x, y)\n",
    "#     # get the slope and intercept of the line\n",
    "#     # print('intercept:', model.intercept_)\n",
    "#     # print('slope:', model.coef_)\n",
    "#     # print('coefficient of determination:', r_sq)\n",
    "#     # calculate and report mean squared error and root mean squared error\n",
    "#     y_pred = model.predict(x)\n",
    "#     # print('mean squared error:', mean_squared_error(y, y_pred))\n",
    "#     # print('mean absolute error:', mean_absolute_error(y, y_pred))\n",
    "#     # print('loss from model score:', 1-model.score(x, y))\n",
    "#     specs = [model.intercept_, model.coef_, r_sq, mean_squared_error(y, y_pred), mean_absolute_error(y, y_pred), 1-model.score(x, y)]\n",
    "    \n",
    "#     return model, y_pred, specs\n",
    "\n",
    "def calc_moe_sdr(x, y, y_pred, slope):\n",
    "    \"\"\"\n",
    "    Given information for a linear regression,\n",
    "    Calculate the Margin Of Error (MOF) and Standard Deviation of Residuals (SDR)\n",
    "    \"\"\"\n",
    "    residuals = y - y_pred\n",
    "    sdr = np.std(residuals)\n",
    "    \n",
    "    df = len(x) - 2 # degrees of freedom for linear regression\n",
    "    se_slope = np.sqrt(mean_squared_error(y, y_pred) / np.sum((x - np.mean(x))**2))\n",
    "    confidence_level = 0.95\n",
    "    alpha = 1 - confidence_level\n",
    "    t_value = t.ppf(1 - alpha / 2, df)\n",
    "    margin_of_error = t_value * se_slope\n",
    "        \n",
    "    return margin_of_error, sdr\n",
    "\n",
    "def linear_regression_full(x, y):\n",
    "    x = np.array(x).reshape((-1, 1))\n",
    "    y = np.array(y)\n",
    "    model = LinearRegression()\n",
    "    model.fit(x, y)\n",
    "    r_sq = model.score(x, y)\n",
    "    \n",
    "    # calculate the confidence interval for the model coefficient (the slope)\n",
    "    moe, sdr = calc_moe_sdr(x, y, model.predict(x), model.coef_[0])\n",
    "    \n",
    "    # calculate the standard deviation of the residuals\n",
    "    residuals = y - model.predict(x)\n",
    "    std_residuals = np.std(residuals)\n",
    "    \n",
    "    \n",
    "    # May want to use model.intercept_ in the future\n",
    "    return model, model.coef_, r_sq, moe, sdr\n",
    "\n",
    "def huber_linear_regression(first, second, epsilon=1.35):\n",
    "    \"\"\"\n",
    "    Use Huber Regressor to fit a linear model to the data. Control amount of outliers with epsilon.\n",
    "    \"\"\"\n",
    "    x = np.array(first).reshape((-1, 1))\n",
    "    y = np.array(second)\n",
    "    model = HuberRegressor(epsilon=epsilon)\n",
    "    model.fit(x, y)\n",
    "    r_sq = model.score(x, y)\n",
    "    \n",
    "    # calculate the confidence interval for the model coefficients\n",
    "    more, sdr = calc_moe_sdr(x, y, model.predict(x), model.coef_[0])\n",
    "\n",
    "    return model, model.coef_, r_sq, more, sdr\n",
    "\n",
    "def ransac_linear_regression(first, second, min_samples=0.95):\n",
    "    \"\"\"\n",
    "    Use RANSAC Regressor to fit a linear model to the data. Control amount of outliers with min_samples.\n",
    "    \"\"\"\n",
    "    x = np.array(first).reshape((-1, 1))\n",
    "    y = np.array(second)\n",
    "    model = RANSACRegressor(base_estimator=LinearRegression(), min_samples=min_samples)\n",
    "    model.fit(x, y)\n",
    "    r_sq = model.score(x, y)\n",
    "    # calculate the confidence interval for the model coefficients\n",
    "    moe, sdr = calc_moe_sdr(x, y, model.predict(x), model.estimator_.coef_)\n",
    "    \n",
    "    return model, model.estimator_.coef_, r_sq, moe, sdr\n",
    "\n",
    "def sort_relative(x, y):\n",
    "    # sort x and apply the same permutation to y\n",
    "    # return x_new and y_new\n",
    "    # sort x and get the permutation\n",
    "    perm = np.argsort(x)\n",
    "    # apply the permutation to x and y\n",
    "    x_new = list(np.array(x)[perm])\n",
    "    y_new = list(np.array(y)[perm])\n",
    "    return x_new, y_new\n",
    "\n",
    "def skip_zeros(first, second):\n",
    "    # chunk x and y to 20 chunks, remove chunks that have more than perc0 % zeros in either x or y from both x and y\n",
    "    # put back chunks together and return as x_new and y_new\n",
    "    #first, second = Physlr.sort_relative(first, second)\n",
    "        \n",
    "    perc0 = 0.70\n",
    "    chunk_count = 30\n",
    "    first_overlapping = []\n",
    "    second_overlapping = []\n",
    "    chunk_size = int(len(first)/chunk_count)\n",
    "    \n",
    "    \n",
    "    for i in range(chunk_count):\n",
    "        first_chunk = first[i*chunk_size:(i+1)*chunk_size]\n",
    "        second_chunk = second[i*chunk_size:(i+1)*chunk_size]\n",
    "        if (first_chunk.count(0) > (perc0*chunk_size)) or (second_chunk.count(0) > (perc0*chunk_size)):\n",
    "            continue\n",
    "        else:\n",
    "            first_overlapping.extend(first_chunk)\n",
    "            second_overlapping.extend(second_chunk)\n",
    "        \n",
    "    return first_overlapping, second_overlapping\n",
    "\n",
    "def plot_all(x, y, x_new, y_new, y_pred, specs):\n",
    "# plot the data and the fitted line\n",
    "    plt.scatter(x, y, s=0.1, c='y', marker=\"o\")\n",
    "    plt.scatter(x_new, y_new, s=0.1, c='r', marker=\"o\")\n",
    "    plt.plot(x_new, y_pred, color='blue')\n",
    "    plt.xlabel(\"Index of minimizer in first line\")\n",
    "    plt.ylabel(\"Index of minimizer in second line\")\n",
    "    #plt.title(\"Index of minimizer in first line vs. Index of minimizer in second line\")\n",
    "    plt.title(\".\")\n",
    "    # print the specs on the plot on top left corner if the slope is positive, and on top right corner if the slope is negative\n",
    "    if specs[1][0] > 0:\n",
    "        plt.text(0.05, 0.95, \"intercept: \" + str(round(specs[0], 2)) + \"\\nslope: \" + str(round(specs[1][0], 2)) + \"\\nR^2: \" + str(round(specs[2], 2)) + \"\\nMSE: \" + str(round(specs[3], 2)) + \"\\nMAE: \" + str(round(specs[4], 2)) + \"\\nloss: \" + str(round(specs[5], 2)), horizontalalignment='left', verticalalignment='top', transform=plt.gca().transAxes)\n",
    "        #plt.text(0.05, 0.95, \"intercept: \" + str(round(specs[0], 2)) + \"\\nslope: \" + str(round(specs[1][0], 2)) + \"\\nR^2: \" + str(round(specs[2], 2)) + \"\\nMSE: \" + str(round(specs[3], 2)) + \"\\nMAE: \" + str(round(specs[4], 2)) + \"\\nloss: \" + str(round(specs[5], 2)), transform=plt.gca().transAxes)\n",
    "    else:\n",
    "        plt.text(0.95, 0.95, \"intercept: \" + str(round(specs[0], 2)) + \"\\nslope: \" + str(round(specs[1][0], 2)) + \"\\nR^2: \" + str(round(specs[2], 2)) + \"\\nMSE: \" + str(round(specs[3], 2)) + \"\\nMAE: \" + str(round(specs[4], 2)) + \"\\nloss: \" + str(round(specs[5], 2)), horizontalalignment='right', verticalalignment='top', transform=plt.gca().transAxes)\n",
    "    \n",
    "    #plt.text(0.05, 0.95, \"intercept: \" + str(round(specs[0], 2)) + \"\\nslope: \" + str(round(specs[1][0], 2)) + \"\\nR^2: \" + str(round(specs[2], 2)) + \"\\nMSE: \" + str(round(specs[3], 2)) + \"\\nMAE: \" + str(round(specs[4], 2)) + \"\\nloss: \" + str(round(specs[5], 2)), transform=plt.gca().transAxes)\n",
    "    \n",
    "    plt.show()\n",
    "    # plot the residuals\n",
    "    plt.scatter(x_new, y_new-y_pred, s=0.1, c='r', marker=\"o\")\n",
    "    plt.xlabel(\"Index of minimizer in first line\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    # plot y = 0\n",
    "    plt.axhline(y=0, color='k', linestyle='--')\n",
    "    #plt.title(\"Index of minimizer in first line vs. Residuals\")\n",
    "    plt.title(\"Residuals\")\n",
    "    plt.show()\n",
    "    \n",
    "def plot_all_2(x, y, miss1, miss2, y_pred, coef, r_sq, moe, sdr):\n",
    "    plt.scatter(x, y, s=0.2, c='g', marker=\"o\")\n",
    "    # plot the missing minimizers miss1 on x axis and miss2 on y axis\n",
    "    plt.scatter(miss1, [0]*len(miss1), s=0.15, c='r', marker=\"o\")\n",
    "    plt.scatter([0]*len(miss2), miss2, s=0.15, c='r', marker=\"o\")\n",
    "    # something like plt.plot(x, y_pred, color='blue') but dotted line\n",
    "    plt.plot(x, y_pred, color='blue', linestyle='dotted')\n",
    "    \n",
    "    plt.xlabel(\"Minimizers' loci on first read\")\n",
    "    plt.ylabel(\"Minimizers' loci on second read\")\n",
    "    #plt.title(\"Minimizers' loci on first read vs. Minimizers' loci on second read\")\n",
    "    plt.title(\".\")\n",
    "    # print the specs on the plot on top left corner if the slope is positive, and on top right corner if the slope is negative\n",
    "    print(\"coef: \", coef[0])\n",
    "    print(\"r_sq: \", r_sq)\n",
    "    print(\"moe: \", moe)\n",
    "    print(\"sdr: \", sdr)\n",
    "    if coef > 0:\n",
    "        # plot coef, r_sq, and ci\n",
    "        plt.text(0.05, 0.95, \"R^2: \" + str(round(r_sq, 2)) + \"\\nSlope: \" + str(round(coef[0], 5)) + \"\\n Slope MoE: -/+\" + str(round(moe, 4)) + \"\\n SDR: \" + str(round(sdr, 2)), horizontalalignment='left', verticalalignment='top', transform=plt.gca().transAxes)\n",
    "        #plt.text(0.05, 0.95, \"intercept: \" + str(round(specs[0], 2)) + \"\\nslope: \" + str(round(specs[1][0], 2)) + \"\\nR^2: \" + str(round(specs[2], 2)) + \"\\nMSE: \" + str(round(specs[3], 2)) + \"\\nMAE: \" + str(round(specs[4], 2)) + \"\\nloss: \" + str(round(specs[5], 2)), horizontalalignment='left', verticalalignment='top', transform=plt.gca().transAxes)\n",
    "        #plt.text(0.05, 0.95, \"intercept: \" + str(round(specs[0], 2)) + \"\\nslope: \" + str(round(specs[1][0], 2)) + \"\\nR^2: \" + str(round(specs[2], 2)) + \"\\nMSE: \" + str(round(specs[3], 2)) + \"\\nMAE: \" + str(round(specs[4], 2)) + \"\\nloss: \" + str(round(specs[5], 2)), transform=plt.gca().transAxes)\n",
    "    else:\n",
    "        # top right corner: plot coef, r_sq, and ci\n",
    "        plt.text(0.95, 0.95, \"R^2: \" + str(round(r_sq, 2)) + \"\\nSlope: \" + str(round(coef[0], 2)) + \"\\n Slope MoE: -/+\" + str(round(moe, 2)) + \"\\n SDR: \" + str(round(sdr, 2)), horizontalalignment='right', verticalalignment='top', transform=plt.gca().transAxes)\n",
    "        #plt.text(0.95, 0.95, \"intercept: \" + str(round(specs[0], 2)) + \"\\nslope: \" + str(round(specs[1][0], 2)) + \"\\nR^2: \" + str(round(specs[2], 2)) + \"\\nMSE: \" + str(round(specs[3], 2)) + \"\\nMAE: \" + str(round(specs[4], 2)) + \"\\nloss: \" + str(round(specs[5], 2)), horizontalalignment='right', verticalalignment='top', transform=plt.gca().transAxes)\n",
    "    plt.show()\n",
    "\n",
    "def file_reader_physlr(file_full_ad):\n",
    "    # store barcode to minimizers in a dictionary from bx to a list of tuples like (mx_pos and mx_value)\n",
    "    nametomxs = {}\n",
    "    with open(file_full_ad, 'r') as file:\n",
    "        for line in file:\n",
    "            fields = line.split(\"\\t\", 1)\n",
    "            if len(fields) < 2:\n",
    "                continue\n",
    "            name = fields[0]\n",
    "            # mxs = minimizers = line[1].split(' ')\n",
    "            posmxs = []\n",
    "            for mx_pos in fields[1].split():\n",
    "                if \":\" not in mx_pos:\n",
    "                    print(\"Error: no locations included\", file_full_ad)\n",
    "                    sys.exit(1)\n",
    "                mx, pos = mx_pos.split(\":\", 1)\n",
    "                posmxs.append((int(pos), int(mx)))\n",
    "            nametomxs[name] = posmxs\n",
    "    return nametomxs\n",
    "\n",
    "def file_reader(file_full_ad):\n",
    "    # initialize the data structure\n",
    "    barcode_to_minimizer = {}\n",
    "    barcode_to_minimizerloc = {}\n",
    "    # read the file\n",
    "    with open(file_full_ad, 'r') as file:\n",
    "        line = file.readline().strip().split('\\t')\n",
    "        barcode_name = line[0]\n",
    "        minimizers = line[1].split(' ')\n",
    "        # each minimizers is formatted like minhash:minloc, split them from : and store them in two lists minhash and minloc \n",
    "        minhash = []\n",
    "        minloc = []\n",
    "        for element in minimizers:\n",
    "            minhash.append(int(element.split(':')[0]))\n",
    "            minloc.append(int(element.split(':')[1]))\n",
    "        barcode_to_minimizer[barcode_name] = [int(x) for x in minhash]\n",
    "        barcode_to_minimizerloc[barcode_name] = [int(x) for x in minloc] \n",
    "        line = file.readline().strip().split('\\t')\n",
    "        barcode_name = line[0]\n",
    "        minimizers = line[1].split(' ')\n",
    "        minhash = []\n",
    "        minloc = []\n",
    "        for element in minimizers:\n",
    "            minhash.append(int(element.split(':')[0]))\n",
    "            minloc.append(int(element.split(':')[1]))       \n",
    "        barcode_to_minimizer[barcode_name] = [int(x) for x in minhash]\n",
    "        barcode_to_minimizerloc[barcode_name] = [int(x) for x in minloc]\n",
    "    print(\"size of dictionary: \", len(barcode_to_minimizer))\n",
    "    print(\"first item in the dictionary: \", list(barcode_to_minimizer.items())[0])\n",
    "    print(\"second item in the dictionary: \", list(barcode_to_minimizer.items())[1])\n",
    "    # grab the first item in the dictionary\n",
    "    first = list(barcode_to_minimizer.items())[0]\n",
    "    first_loc = list(barcode_to_minimizerloc.items())[0]\n",
    "    second = list(barcode_to_minimizer.items())[1]\n",
    "    second_loc = list(barcode_to_minimizerloc.items())[1]   \n",
    "    return first, first_loc, second, second_loc\n",
    "\n",
    "######################### Functions\n",
    "######################################################################################################################################################\n",
    "######################################################################################################################################################\n",
    "######################### Usage\n",
    "\n",
    "file_ad = '/projects/btl_scratch/aafshinfard/projects/physlr2/experiments/datasets/aligned/pairs9/physlr_bxtomx_pair18'\n",
    "file_ad = '/projects/btl_scratch/aafshinfard/projects/physlr2/experiments/chm13_guppy_v5/rle_data/physlr_pair18_indexlr2/data'\n",
    "#file_name = 'reads.63X.rle.k40-w32.n100-5000.c2-x.physlr.true-false.pair18.true_pair1.tsv'\n",
    "#file_name = 'reads.63X.rle.k40-w32.n100-5000.c2-x.physlr.true-false.pair18.false_pair1.tsv'\n",
    "# file_name = 'pairs18.seqtk.k40-w32.n100-5000.c2-x.physlr.true_pair1.tsv'\n",
    "# file_name = 'pairs18.seqtk.k40-w32.n100-5000.c2-x.physlr.false_pair6.tsv'\n",
    "file_name_pre = 'pairs18.seqtk.k40-w32.n100-5000.c2-x.physlr.false_pair'\n",
    "#file_name_pre = 'pairs18.seqtk.k40-w32.n100-5000.c2-x.physlr.true_pair'\n",
    "#file_full_ad = file_ad + '/' + file_name\n",
    "\n",
    "# build_location_pairs\n",
    "# read files by aataching 1 to 9 to the end of file_name_pre\n",
    "\n",
    "# for i in range(1, 10):\n",
    "#     first, first_loc, second, second_loc = file_reader(file_ad + '/' + file_name_pre + str(i) + '.tsv') \n",
    "#     indices_first, indices_second = build_location_pairs(first, first_loc, second, second_loc)\n",
    "#     new_indices_first, new_indices_second = sort_relative(indices_first, indices_second)\n",
    "#     new2_indices_first, new2_indices_second = skip_zeros(new_indices_first, new_indices_second)\n",
    "#     model, y_pred, specs = linear_regression_full(new2_indices_first, new2_indices_second)\n",
    "#     plot_all(new_indices_first, new_indices_second, new2_indices_first, new2_indices_second, y_pred, specs)\n",
    "\n",
    "for i in range(1, 10):\n",
    "    bxtomxs = file_reader_physlr(file_ad + '/' + file_name_pre + str(i) + '.tsv')\n",
    "    # extract the first and second key in the dict bxtmxs\n",
    "    bx1 = list(bxtomxs.keys())[0]\n",
    "    bx2 = list(bxtomxs.keys())[1]\n",
    "    comm_mxs, miss_1, miss_2 = overlap_read_pairs(bxtomxs, bx1, bx2)\n",
    "    x, y = make_LR_arrays(comm_mxs)\n",
    "    #model, coef, r_sq, moe, sdr = linear_regression_full(x, y)\n",
    "    model, coef, r_sq, moe, sdr = ransac_linear_regression(x, y)\n",
    "    plot_all_2(x, y, list(miss_1.values()), list(miss_2.values()), model.predict(x), coef, r_sq, moe, sdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physlr Goldrush\n",
    "# Physlr-goldrush\n",
    "\n",
    "\n",
    "# read files that contain one column of many numbers.\n",
    "\n",
    "#add_prefix = '/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr-goldrush/rle/default/read_analysis/'\n",
    "add_prefix = '/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/hg01243/physlr-goldrush/rle/default/read_analysis/'\n",
    "\n",
    "add_prefix = '/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/hg002/physlr-goldrush/rle/default/read_analysis/'\n",
    "add_prefix = '/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/hg02055/physlr-goldrush/rle/default/read_analysis/'\n",
    "\n",
    "add1= add_prefix + 'CHM13.d1.fq.read_length'\n",
    "add2= add_prefix + 'CHM13.d2.fq.read_length'\n",
    "# add3= add_prefix + 'HG01243.d3.fq.read_length'\n",
    "add4= add_prefix + 'CHM13.d4.fq.read_length'\n",
    "\n",
    "add1= add_prefix + 'HG01243.d1.fq.read_length'\n",
    "add2= add_prefix + 'HG01243.d2.fq.read_length'\n",
    "# add3= add_prefix + 'HG01243.d3.fq.read_length'\n",
    "add4= add_prefix + 'HG01243.d4.fq.read_length'\n",
    "\n",
    "add1= add_prefix + 'HG002.d1.fq.read_length'\n",
    "add2= add_prefix + 'HG002.d2.fq.read_length'\n",
    "# add3= add_prefix + 'HG01243.d3.fq.read_length'\n",
    "add4= add_prefix + 'HG002.d4.fq.read_length'\n",
    "\n",
    "\n",
    "add1= add_prefix + 'HG02055.d1.fq.read_length'\n",
    "add2= add_prefix + 'HG02055.d2.fq.read_length'\n",
    "# add3= add_prefix + 'HG01243.d3.fq.read_length'\n",
    "add4= add_prefix + 'HG02055.d4.fq.read_length'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# add2='/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr-goldrush/rle/default/read_analysis/HG01243.d2.fq.read_length'\n",
    "# #add3='/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr-goldrush/rle/default/read_analysis/HG01243.d3.fq.read_length'\n",
    "# add4='/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr-goldrush/rle/default/read_analysis/HG01243.d4.fq.read_length'\n",
    "add5='/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr-goldrush/rle/default/read_analysis/CHM13.rle.physlr.mol.multi.fq_read_length'\n",
    "\n",
    "\n",
    "# plot histograms for numbers in each file and compare them\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def read_file(file_ad):\n",
    "    with open(file_ad, 'r') as file:\n",
    "        data = file.readlines()\n",
    "    data = [int(x) for x in data]\n",
    "    return data\n",
    "\n",
    "data1 = read_file(add1)\n",
    "data2 = read_file(add2)\n",
    "#data3 = read_file(add3)\n",
    "data4 = read_file(add4)\n",
    "data5= read_file(add5)\n",
    "\n",
    "# plot histograms for data1, data2, data3, and data4 all in one plot but each in a different color\n",
    "# plot y axis in log scale\n",
    "# set size of each bin to 200\n",
    "bin_width = 200\n",
    "num_bins1 = int((max(data1) - min(data1)) / bin_width)\n",
    "num_bins2 = int((max(data2) - min(data2)) / bin_width)\n",
    "#num_bins3 = int((max(data3) - min(data3)) / bin_width)\n",
    "num_bins4 = int((max(data4) - min(data4)) / bin_width)\n",
    "num_bins5 = int((max(data5) - min(data5)) / bin_width)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#plt.hist(data2, bins=num_bins2, alpha=0.5, label='d2', color='r')\n",
    "#plt.hist(data3, bins=num_bins3, alpha=0.5, label='data3', color='b')\n",
    "plt.hist(data4, bins=num_bins4, alpha=0.8, label='all read', color='y')\n",
    "plt.hist(data1, bins=num_bins1, alpha=0.8, label='Physlr-filtered', color='g')\n",
    "\n",
    "# print sum of data1, data2, data3, and data4\n",
    "print(\"sum of d1: \", sum(data1))\n",
    "print(\"sum of d2: \", sum(data2))\n",
    "#print(\"sum of data3: \", sum(data3))\n",
    "print(\"sum of d4: \", sum(data4))\n",
    "\n",
    "# x-axis label: read length\n",
    "plt.xlabel('Read Length')\n",
    "# y-axis label: Number of Reads\n",
    "plt.ylabel('Number of Reads')\n",
    "# title: Histogram of Read Lengths\n",
    "plt.title('Histogram of Read Lengths')\n",
    "\n",
    "#plt.yscale('log')\n",
    "# set x limit at 5e5\n",
    "#plt.ylim(0, 5e5)\n",
    "plt.ylim(0, 5e4)\n",
    "plt.xlim(0, 1.5e5)\n",
    "# plt.ylim(0, 15e4)\n",
    "# plt.xlim(0, 0.5e5)\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# clear plt\n",
    "plt.clf()\n",
    "\n",
    "plt.hist(data2, bins=num_bins2, alpha=0.8, label='Physlr d2', color='r')\n",
    "plt.hist(data1, bins=num_bins1, alpha=0.8, label='Physlr d1 (-chimerics)', color='g')\n",
    "# x-axis label: read length\n",
    "plt.xlabel('Read Length')\n",
    "# y-axis label: Number of Reads\n",
    "plt.ylabel('Number of Reads')\n",
    "# title: Histogram of Read Lengths\n",
    "plt.title('Histogram of Read Lengths')\n",
    "plt.ylim(0, 7e3)\n",
    "plt.xlim(0, 2e5)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# clear plt\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "plt.hist(data5, bins=num_bins5, alpha=1, label='Physlr chimeric reads', color='r')\n",
    "# x-axis label: read length\n",
    "plt.xlabel('Read Length')\n",
    "# y-axis label: Number of Reads\n",
    "plt.ylabel('Number of Reads')\n",
    "# title: Histogram of Read Lengths\n",
    "plt.title('Histogram of Read Lengths')\n",
    "\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read columns of the second row from the following files and store them in a file\n",
    "# the files have three rows, third row is not important and we will ignore it and first row is the header, the first two rows look like this:\n",
    "# |Assembly|NG50|NGA50|# misassemblies|# local misassemblies|Genome fraction (%)|Duplication ratio|Total length|Unaligned length|# unaligned contigs|# N's per 100 kbp|# mismatches per 100 kbp|# indels per 100 kbp\n",
    "# |goldrush|10,013,881|5,345,781|2,981|1,204|94.081|1.045|2,891,422,627|2,895,011|43 + 733 part|115.41|153.99|69.33\n",
    "# ignore | and store all the values in a data structure\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "add1 = \"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/hg002/physlr-goldrush/rle/default/d1/d1+d3/quast_*_quast.tsv\"\n",
    "add2 = \"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/hg002/physlr-goldrush/rle/default/d2/d2+d4/quast_*_quast.tsv\"\n",
    "add3 = \"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/hg002/physlr-goldrush/rle/m95/d1/d1+d3/quast_*_quast.tsv\"\n",
    "add4 = \"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/hg002/physlr-goldrush/rle/m95/d2/d2+d4/quast_*_quast.tsv\"\n",
    "\n",
    "add1 = \"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr-goldrush/rle/default/d1/d1+d3/quast_*_quast.tsv\"\n",
    "add2 = \"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr-goldrush/rle/default/d2/d2+d4/quast_*_quast.tsv\"\n",
    "add3 = \"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr-goldrush/rle/m95/d1/d1+d3/quast_*_quast.tsv\"\n",
    "add4 = \"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr-goldrush/rle/m95/d2/d2+d4/quast_*_quast.tsv\"\n",
    "\n",
    "# now read the files and store the second row in a data structure\n",
    "def read_file(file_ad):\n",
    "    with open(file_ad, 'r') as file:\n",
    "        data = file.readlines()\n",
    "    data = data[1].split('|')[1:-1]\n",
    "    data = [x.strip() for x in data]\n",
    "    return data\n",
    "\n",
    "data1 = read_file(add1)\n",
    "data2 = read_file(add2)\n",
    "data3 = read_file(add3)\n",
    "data4 = read_file(add4)\n",
    "\n",
    "# merge all the data in a single data structure, and add a header to it\n",
    "\n",
    "header = [\"Assembly\", \"NG50\", \"NGA50\", \"# misassemblies\", \"# local misassemblies\", \"Genome fraction (%)\", \"Duplication ratio\", \"Total length\", \"Unaligned length\", \"# unaligned contigs\", \"# N's per 100 kbp\", \"# mismatches per 100 kbp\", \"# indels per 100 kbp\"]\n",
    "data = [header, data1, data2, data3, data4]\n",
    "\n",
    "# now plot NGA50 against misassemblies for all the data in data\n",
    "# first, convert the data to numbers\n",
    "# then plot NGA50 against misassemblies for all the data in data\n",
    "\n",
    "# convert the data to numbers\n",
    "for i in range(1, len(data)):\n",
    "    data[i] = [int(x.replace(',', '')) if x.replace(',', '').isdigit() else float(x) for x in data[i]]\n",
    "    \n",
    "# plot NGA50 against misassemblies for all the data in data\n",
    "# plot y axis in log scale\n",
    "# set size of each bin to 200\n",
    "\n",
    "# plot NGA50 against misassemblies for all the data in data\n",
    "plt.scatter(data[1], data[2], s=0.1, c='r', marker=\"o\", label='d1+d3')\n",
    "plt.scatter(data[3], data[4], s=0.1, c='b', marker=\"o\", label='d2+d4')\n",
    "plt.xlabel(\"NGA50\")\n",
    "plt.ylabel(\"# misassemblies\")\n",
    "plt.title(\"NGA50 vs. # misassemblies\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot quality metrics for GoldRush assemblies with and without Philter \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "cell_lines = ['HG01243', 'HG002', 'CHM13']\n",
    "gr_nga50 = [11.1, 5.3, 14.5]\n",
    "gr_miss = [1741, 2981, 725]\n",
    "gr_miss_local = [4057, 1204, 8959]\n",
    "gr_unaligned = [12.8, 2.9, 33.2]\n",
    "gr_misnmatch = [1181, 154, 663]\n",
    "gr_indel = [899, 69, 470]\n",
    "\n",
    "philter_nga50 = [11.6, 6.4, 19.1]\n",
    "philter_miss = [1486, 2656, 681]\n",
    "philter_miss_local = [2255, 1137, 2229]\n",
    "philter_unaligned = [6.5, 2.9, 9.5]\n",
    "philter_misnmatch = [642, 150, 279]\n",
    "philter_indel = [578, 67, 315]\n",
    "\n",
    "# plot NGA50 against misassemblies for all the cell lines, each with gr_ in blue and philter_ in green\n",
    "# plot the first datapoint in one shape and the second in another shape, and the third in another shape\n",
    "\n",
    "shapes = ['o', 's', 'd']\n",
    "\n",
    "for i in range(len(cell_lines)):\n",
    "    plt.scatter(gr_miss[i], gr_nga50[i], s=150, c='y', marker=shapes[i], label=cell_lines[i] + ' gr')\n",
    "    plt.scatter(philter_miss[i], philter_nga50[i], s=150, c='g', marker=shapes[i], label=cell_lines[i] + ' philter')\n",
    "    \n",
    "# bigger labels\n",
    "plt.xlabel(\"# misassemblies\", fontsize=14)\n",
    "plt.ylabel(\"NGA50\", fontsize=14)\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.title(\"NGA50 vs. # misassemblies\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# use the same plotting concept, but this time NGA50 against local misassemblies\n",
    "shapes = ['o', 's', 'd']\n",
    "\n",
    "for i in range(len(cell_lines)):\n",
    "    plt.scatter(gr_miss_local[i], gr_nga50[i], s=150, c='y', marker=shapes[i], label=cell_lines[i] + ' gr')\n",
    "    plt.scatter(philter_miss_local[i], philter_nga50[i], s=150, c='g', marker=shapes[i], label=cell_lines[i] + ' philter')\n",
    "\n",
    "# bigger labels\n",
    "plt.xlabel(\"# local misassemblies\", fontsize=14)\n",
    "plt.ylabel(\"NGA50\", fontsize=14)\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.title(\"NGA50 vs. # local misassemblies\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# now same concept, but plot mismatches against indels\n",
    "shapes = ['o', 's', 'd']\n",
    "\n",
    "for i in range(len(cell_lines)):\n",
    "    plt.scatter(gr_misnmatch[i], gr_indel[i], s=150, c='y', marker=shapes[i], label=cell_lines[i] + ' gr')\n",
    "    plt.scatter(philter_misnmatch[i], philter_indel[i], s=150, c='g', marker=shapes[i], label=cell_lines[i] + ' philter')\n",
    "\n",
    "# bigger labels\n",
    "plt.xlabel(\"# mismatches per 100 kbp\", fontsize=14)\n",
    "plt.ylabel(\"# indels per 100 kbp\", fontsize=14)\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.title(\"# mismatches per 100 kbp vs. # indels per 100 kbp\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# now plot unaligned length only (1 dimensions) - choose an appropriate visualization technique, not scatter plot necessarily\n",
    "shapes = ['o', 's', 'd']\n",
    "\n",
    "# plot in log scale\n",
    "for i in range(len(cell_lines)):\n",
    "    plt.scatter([\"GoldRush\"], gr_unaligned[i]*1000000, s=150, c='y', marker=shapes[i], label=cell_lines[i] + ' gr')\n",
    "    plt.scatter([\"Philter\"], philter_unaligned[i]*1000000, s=150, c='g', marker=shapes[i], label=cell_lines[i] + ' philter')\n",
    "\n",
    "#plt.yscale('log')    \n",
    "# bigger labels\n",
    "plt.xlabel(\"1\", fontsize=14)\n",
    "plt.ylabel(\"Unaligned length\", fontsize=14)\n",
    "# bigger x and y ticks\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.title(\"Unaligned length\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# read a file with 4 columns of data, and plit column 2 against column 4 in a scatterplot and also density plot\n",
    "file = \"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr_20k_rle/physlr_rle_default/data/reads.63X.20k.rle.k40-w32.n100-50000.physlr.mxs-count.paste.len.sorted.tsv\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def read_file(file_ad):\n",
    "    with open(file_ad, 'r') as file:\n",
    "        data = file.readlines()\n",
    "    data = [x.split() for x in data]\n",
    "    return data\n",
    "\n",
    "data = read_file(file)\n",
    "data = [[x[0], int(x[1]), x[2], int(x[3])] for x in data]\n",
    "\n",
    "# plot column 2 against column 4 in a scatterplot\n",
    "x = [x[1] for x in data]\n",
    "y = [x[3] for x in data]\n",
    "\n",
    "plt.scatter(x, y, s=0.1, c='r', marker=\"o\")\n",
    "plt.xlabel(\"mxs count\")\n",
    "plt.ylabel(\"read length\")\n",
    "\n",
    "plt.title(\"mxs count vs. read length\")\n",
    "xlim = plt.xlim()\n",
    "ylim = plt.ylim()\n",
    "plt.show()\n",
    "\n",
    "plt.xlim(xlim[0]/20,xlim[1]/20)\n",
    "plt.ylim(ylim[0]/20,ylim[1]/20)\n",
    "plt.show()\n",
    "\n",
    "#######\n",
    "# fit a linear regression model to a random subsample of the data and plot the line and also print the slope of the line on the plot\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "# sunsample the data to 10000 points randomly\n",
    "data_temp = data\n",
    "data = pd.DataFrame(data)\n",
    "data = data.sample(n=10000)\n",
    "\n",
    "# fit a linear regression model to the data\n",
    "x = np.array(data[1]).reshape((-1, 1))\n",
    "y = np.array(data[3])\n",
    "model = LinearRegression()\n",
    "model.fit(x, y)\n",
    "r_sq = model.score(x, y)\n",
    "y_pred = model.predict(x)\n",
    "\n",
    "# plot the data and the fitted line\n",
    "\n",
    "plt.scatter(x, y, s=0.1, c='r', marker=\"o\")\n",
    "plt.plot(x, y_pred, color='blue')\n",
    "plt.xlabel(\"mxs count\")\n",
    "plt.ylabel(\"read length\")\n",
    "plt.title(\"mxs count vs. read length\")\n",
    "# print the slope on the plot\n",
    "plt.text(0.05, 0.95, \"slope: \" + str(round(model.coef_[0], 2)), horizontalalignment='left', verticalalignment='top', transform=plt.gca().transAxes)\n",
    "# set the x and y limits to be same as previous plot\n",
    "plt.xlim(xlim[0]/20,xlim[1]/20)\n",
    "plt.ylim(ylim[0]/20,ylim[1]/20)\n",
    "plt.show()\n",
    "\n",
    "# plot a 2-d density plot of the data\n",
    "sns.kdeplot(x=data[1], y=data[3], cmap=\"Blues\", fill=True, bw_adjust=0.5)\n",
    "plt.xlabel(\"mxs count\")\n",
    "plt.ylabel(\"read length\")\n",
    "plt.title(\"mxs count vs. read length\")\n",
    "#plot the regression line on top of the density plot\n",
    "plt.plot(x, y_pred, color='red')\n",
    "# set the x and y limits to be same as previous plot\n",
    "plt.xlim(xlim[0]/20,xlim[1]/20)\n",
    "plt.ylim(ylim[0]/20,ylim[1]/20)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# divide lenght of reads (column 4) by mxs count (column 2) and plot the result in a histogram\n",
    "data = data_temp\n",
    "data = pd.DataFrame(data)\n",
    "data = data.sample(n=10000)\n",
    "x = np.array(data[1])\n",
    "y = np.array(data[3])\n",
    "y = y/x\n",
    "plt.hist(y, bins=100, alpha=0.8, label='y', color='y')\n",
    "plt.xlabel(\"read length/mxs count\")\n",
    "plt.ylabel(\"Number of reads\")\n",
    "plt.title(\"read length/mxs count\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlim(0, 750)\n",
    "plt.ylim(0, 2000)\n",
    "plt.show()\n",
    "\n",
    "# print min and max of x and y\n",
    "print(\"min of x: \", min(x))\n",
    "print(\"max of x: \", max(x))\n",
    "print(\"min of y: \", min(y))\n",
    "print(\"max of y: \", max(y))\n",
    "\n",
    "# plot cumulative distribution of y (from 1)\n",
    "y = sorted(y)\n",
    "y = [x for x in y if x > 1]\n",
    "plt.plot(y, np.linspace(0, 1, len(y), endpoint=False))\n",
    "plt.xlabel(\"read length/mxs count\")\n",
    "plt.ylabel(\"cumulative distribution\")\n",
    "plt.title(\"cumulative distribution of read length/mxs count\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(y, np.linspace(0, 1, len(y), endpoint=False))\n",
    "plt.xlabel(\"read length/mxs count\")\n",
    "plt.ylabel(\"cumulative distribution\")\n",
    "plt.title(\"cumulative distribution of read length/mxs count\")\n",
    "plt.xlim(20, 100)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# read a file with 4 columns of data, and plit column 2 against column 4 in a scatterplot and also density plot\n",
    "file_all = \"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr_20k_rle/physlr_rle_default/data/reads.63X.20k.rle.k40-w32.n100-50000.physlr.mxs-count.paste.len.sorted.tsv\"\n",
    "\n",
    "file_nonmulti = \"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr_20k_rle/physlr_rle_default/data/reads.63X.20k.rle.k40-w32.n100-50000.physlr.mxs-count.paste.len.sorted.tsv_filtered.NOT_IN.physlr.overlap.m92.5.mol.multi.tsv\"\n",
    "file_multi = \"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr_20k_rle/physlr_rle_default/data/reads.63X.20k.rle.k40-w32.n100-50000.physlr.mxs-count.paste.len.sorted.tsv_filtered_.physlr.overlap.m92.5.mol.multi.tsv\"\n",
    "file_nonmol = \"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr_20k_rle/physlr_rle_default/data/reads.63X.20k.rle.k40-w32.n100-50000.physlr.mxs-count.paste.len.sorted.tsv_filtered.NOT_IN.physlr.overlap.m92.5.mol.tsv\"\n",
    "file_nonoverlap = \"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr_20k_rle/physlr_rle_default/data/reads.63X.20k.rle.k40-w32.n100-50000.physlr.mxs-count.paste.len.sorted.tsv_filtered.NOT_IN.physlr.overlap.m92.5.tsv\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def read_file(file_ad):\n",
    "    with open(file_ad, 'r') as file:\n",
    "        data = file.readlines()\n",
    "    data = [x.split() for x in data]\n",
    "    return data\n",
    "\n",
    "# all data\n",
    "data_all = read_file(file_all)\n",
    "data_all = [[x[0], int(x[1]), x[2], int(x[3])] for x in data_all]\n",
    "\n",
    "# plot column 2 against column 4 in a scatterplot\n",
    "x = [x[1] for x in data_all]\n",
    "y = [x[3] for x in data_all]\n",
    "\n",
    "plt.scatter(x, y, s=0.1, c='r', marker=\"o\")\n",
    "plt.xlabel(\"mxs count\")\n",
    "plt.ylabel(\"read length\")\n",
    "\n",
    "plt.title(\"mxs count vs. read length\")\n",
    "xlim = plt.xlim()\n",
    "ylim = plt.ylim()\n",
    "xlim=(0, 7000)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Other data colored\n",
    "# nonmulti\n",
    "data_nonmulti = read_file(file_nonmulti)\n",
    "data_nonmulti = [[x[0], int(x[1]), x[2], int(x[3])] for x in data_nonmulti]\n",
    "x_nonmulti = [x[1] for x in data_nonmulti]\n",
    "y_nonmulti = [x[3] for x in data_nonmulti]\n",
    "\n",
    "# multi\n",
    "data_multi = read_file(file_multi)\n",
    "data_multi = [[x[0], int(x[1]), x[2], int(x[3])] for x in data_multi]\n",
    "x_multi = [x[1] for x in data_multi]\n",
    "y_multi = [x[3] for x in data_multi]\n",
    "\n",
    "# nonmol\n",
    "data_nonmol = read_file(file_nonmol)\n",
    "data_nonmol = [[x[0], int(x[1]), x[2], int(x[3])] for x in data_nonmol]\n",
    "x_nonmol = [x[1] for x in data_nonmol]\n",
    "y_nonmol = [x[3] for x in data_nonmol]\n",
    "\n",
    "# nonoverlap\n",
    "data_nonoverlap = read_file(file_nonoverlap)\n",
    "data_nonoverlap = [[x[0], int(x[1]), x[2], int(x[3])] for x in data_nonoverlap]\n",
    "x_nonoverlap = [x[1] for x in data_nonoverlap]\n",
    "y_nonoverlap = [x[3] for x in data_nonoverlap]\n",
    "\n",
    "plt.scatter(x_nonmol, y_nonmol, s=0.1, c='b', marker=\"o\", label='nonmol')\n",
    "plt.xlabel(\"mxs count\")\n",
    "plt.ylabel(\"read length\")\n",
    "plt.title(\"nonmol - mxs count vs. read length\")\n",
    "plt.legend(loc='upper right')\n",
    "xlim = plt.xlim()\n",
    "ylim = plt.ylim()\n",
    "xlim=(0, 7000)\n",
    "plt.xlim(xlim)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.scatter(x_nonmulti, y_nonmulti, s=0.1, c='g', marker=\"o\", label='nonmulti')\n",
    "plt.xlabel(\"mxs count\")\n",
    "plt.ylabel(\"read length\")\n",
    "plt.title(\"nonmulti - mxs count vs. read length\")\n",
    "plt.legend(loc='upper right')\n",
    "# set to same xlim and ylim from previous\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(ylim)\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(x_nonoverlap, y_nonoverlap, s=0.1, c='y', marker=\"o\", label='nonoverlap')\n",
    "plt.xlabel(\"mxs count\")\n",
    "plt.ylabel(\"read length\")\n",
    "plt.title(\"nonoverlap - mxs count vs. read length\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(ylim)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.scatter(x_multi, y_multi, s=0.1, c='r', marker=\"o\", label='multi')\n",
    "plt.xlabel(\"mxs count\")\n",
    "plt.ylabel(\"read length\")\n",
    "plt.title(\"multi - mxs count vs. read length\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(ylim)\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(x_nonmol, y_nonmol, s=0.1, c='b', marker=\"o\", label='nonmol')\n",
    "plt.scatter(x_nonmulti, y_nonmulti, s=0.1, c='g', marker=\"o\", label='nonmulti')\n",
    "plt.scatter(x_nonoverlap, y_nonoverlap, s=0.1, c='y', marker=\"o\", label='nonoverlap')\n",
    "plt.scatter(x_multi, y_multi, s=0.1, c='r', marker=\"o\", label='multi')\n",
    "plt.xlabel(\"mxs count\")\n",
    "plt.ylabel(\"read length\")\n",
    "plt.title(\"mxs count vs. read length\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(ylim)\n",
    "plt.show()\n",
    "\n",
    "# print size of each all x_ data\n",
    "print(\"size of x_all: \", len(x))\n",
    "print(\"size of x_nonmulti: \", len(x_nonmulti))\n",
    "print(\"size of x_multi: \", len(x_multi))\n",
    "print(\"size of x_nonmol: \", len(x_nonmol))\n",
    "print(\"size of x_nonoverlap: \", len(x_nonoverlap))\n",
    "\n",
    "\n",
    "############################################################\n",
    "# plot them again but this time as density plots\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "# all data\n",
    "data_all = pd.DataFrame(data_all)\n",
    "data_all = data_all.sample(n=10000)\n",
    "x = np.array(data_all[1])\n",
    "y = np.array(data_all[3])\n",
    "# sns.kdeplot(x=x, y=y, cmap=\"Blues\", fill=True, bw_adjust=0.5)\n",
    "# plt.xlabel(\"mxs count\")\n",
    "# plt.ylabel(\"read length\")\n",
    "# plt.title(\"mxs count vs. read length\")\n",
    "# plt.xlim(xlim)\n",
    "# plt.ylim(ylim)\n",
    "# plt.show()\n",
    "\n",
    "# nonmulti\n",
    "data_nonmulti = pd.DataFrame(data_nonmulti)\n",
    "data_nonmulti = data_nonmulti.sample(n=10000)\n",
    "x = np.array(data_nonmulti[1])\n",
    "y = np.array(data_nonmulti[3])\n",
    "sns.kdeplot(x=x, y=y, cmap=\"Blues\", fill=True, bw_adjust=0.5)\n",
    "plt.xlabel(\"mxs count\")\n",
    "plt.ylabel(\"read length\")\n",
    "plt.title(\"nonmulti - mxs count vs. read length\")\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(ylim)\n",
    "plt.show()\n",
    "\n",
    "# multi\n",
    "data_multi = pd.DataFrame(data_multi)\n",
    "data_multi = data_multi.sample(n=10000)\n",
    "x = np.array(data_multi[1])\n",
    "y = np.array(data_multi[3])\n",
    "sns.kdeplot(x=x, y=y, cmap=\"Blues\", fill=True, bw_adjust=0.5)\n",
    "plt.xlabel(\"mxs count\")\n",
    "plt.ylabel(\"read length\")\n",
    "plt.title(\"multi - mxs count vs. read length\")\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(ylim)\n",
    "plt.show()\n",
    "\n",
    "# nonmol\n",
    "data_nonmol = pd.DataFrame(data_nonmol)\n",
    "data_nonmol = data_nonmol.sample(n=10000)\n",
    "x = np.array(data_nonmol[1])\n",
    "y = np.array(data_nonmol[3])\n",
    "sns.kdeplot(x=x, y=y, cmap=\"Blues\", fill=True, bw_adjust=0.5)\n",
    "plt.xlabel(\"mxs count\")\n",
    "plt.ylabel(\"read length\")\n",
    "plt.title(\"nonmol - mxs count vs. read length\")\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(ylim)\n",
    "plt.show()\n",
    "\n",
    "# nonoverlap\n",
    "data_nonoverlap = pd.DataFrame(data_nonoverlap)\n",
    "data_nonoverlap = data_nonoverlap.sample(n=10000)\n",
    "x = np.array(data_nonoverlap[1])\n",
    "y = np.array(data_nonoverlap[3])\n",
    "sns.kdeplot(x=x, y=y, cmap=\"Blues\", fill=True, bw_adjust=0.5)\n",
    "plt.xlabel(\"mxs count\")\n",
    "plt.ylabel(\"read length\")\n",
    "plt.title(\"nonoverlap - mxs count vs. read length\")\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(ylim)\n",
    "plt.show()\n",
    "\n",
    "# plot them all in one plot\n",
    "#sns.kdeplot(x=x, y=y, cmap=\"Blues\", fill=True, bw_adjust=0.5, label='all')\n",
    "sns.kdeplot(x=x_nonmulti, y=y_nonmulti, cmap=\"Greens\", fill=True, bw_adjust=0.5, label='nonmulti')\n",
    "sns.kdeplot(x=x_multi, y=y_multi, cmap=\"Reds\", fill=True, bw_adjust=0.5, label='multi')\n",
    "sns.kdeplot(x=x_nonmol, y=y_nonmol, cmap=\"Blues\", fill=True, bw_adjust=0.5, label='nonmol')\n",
    "sns.kdeplot(x=x_nonoverlap, y=y_nonoverlap, cmap=\"Oranges\", fill=True, bw_adjust=0.5, label='nonoverlap')\n",
    "plt.xlabel(\"mxs count\")\n",
    "plt.ylabel(\"read length\")\n",
    "plt.title(\"mxs count vs. read length\")\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(ylim)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_all = \"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr_20k_rle/physlr_rle_default/data/reads.63X.20k.rle.k40-w32.n100-50000.physlr.mxs-count.paste.len.sorted.tsv\"\n",
    "file_nonmulti = \"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr_20k_rle/physlr_rle_default/data/reads.63X.20k.rle.k40-w32.n100-50000.physlr.mxs-count.paste.len.sorted.tsv_filtered.NOT_IN.physlr.overlap.m92.5.mol.multi.tsv\"\n",
    "file_multi = \"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr_20k_rle/physlr_rle_default/data/reads.63X.20k.rle.k40-w32.n100-50000.physlr.mxs-count.paste.len.sorted.tsv_filtered_.physlr.overlap.m92.5.mol.multi.tsv\"\n",
    "file_nonmol = \"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr_20k_rle/physlr_rle_default/data/reads.63X.20k.rle.k40-w32.n100-50000.physlr.mxs-count.paste.len.sorted.tsv_filtered.NOT_IN.physlr.overlap.m92.5.mol.tsv\"\n",
    "file_nonoverlap = \"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr_20k_rle/physlr_rle_default/data/reads.63X.20k.rle.k40-w32.n100-50000.physlr.mxs-count.paste.len.sorted.tsv_filtered.NOT_IN.physlr.overlap.m92.5.tsv\"\n",
    "\n",
    "# change directory to /projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr_rle/default/data/\n",
    "# and file prefix to CHM13.rle. instead of reads.63X.20k.rle.\n",
    "# so /projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr_rle/default/data/CHM13.rle.\n",
    "\n",
    "file_all = \"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr_rle/default/data/CHM13.rle.k40-w32.n100-50000.physlr.mxs-count.paste.len.sorted.tsv\"\n",
    "file_nonmulti = \"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr_rle/default/data/CHM13.rle.k40-w32.n100-50000.physlr.mxs-count.paste.len.sorted.tsv_filtered.NOT_IN.physlr.overlap.m92.5.mol.multi.tsv\"\n",
    "file_multi = \"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr_rle/default/data/CHM13.rle.k40-w32.n100-50000.physlr.mxs-count.paste.len.sorted.tsv_filtered_.physlr.overlap.m92.5.mol.multi.tsv\"\n",
    "file_nonmol = \"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr_rle/default/data/CHM13.rle.k40-w32.n100-50000.physlr.mxs-count.paste.len.sorted.tsv_filtered.NOT_IN.physlr.overlap.m92.5.mol.tsv\"\n",
    "file_nonoverlap = \"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr_rle/default/data/CHM13.rle.k40-w32.n100-50000.physlr.mxs-count.paste.len.sorted.tsv_filtered.NOT_IN.physlr.overlap.m92.5.tsv\"\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def read_file(file_ad):\n",
    "    with open(file_ad, 'r') as file:\n",
    "        data = file.readlines()\n",
    "    data = [x.split() for x in data]\n",
    "    return data\n",
    "\n",
    "# all data\n",
    "data_all = read_file(file_all)\n",
    "data_all = [[x[0], int(x[1]), x[2], int(x[3])] for x in data_all]\n",
    "\n",
    "# plot column 2 against column 4 in a scatterplot\n",
    "# x = [x[1] for x in data_all]\n",
    "# y = [x[3] for x in data_all]\n",
    "\n",
    "# plt.scatter(x, y, s=0.1, c='r', marker=\"o\")\n",
    "# plt.xlabel(\"mxs count\")\n",
    "# plt.ylabel(\"read length\")\n",
    "\n",
    "# plt.title(\"mxs count vs. read length\")\n",
    "# xlim = plt.xlim()\n",
    "# ylim = plt.ylim()\n",
    "# xlim=(0, 7000)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# Other data colored\n",
    "# nonmulti\n",
    "data_nonmulti = read_file(file_nonmulti)\n",
    "data_nonmulti = [[x[0], int(x[1]), x[2], int(x[3])] for x in data_nonmulti]\n",
    "x_nonmulti = [x[1] for x in data_nonmulti]\n",
    "y_nonmulti = [x[3] for x in data_nonmulti]\n",
    "\n",
    "# multi\n",
    "data_multi = read_file(file_multi)\n",
    "data_multi = [[x[0], int(x[1]), x[2], int(x[3])] for x in data_multi]\n",
    "x_multi = [x[1] for x in data_multi]\n",
    "y_multi = [x[3] for x in data_multi]\n",
    "\n",
    "# nonmol\n",
    "data_nonmol = read_file(file_nonmol)\n",
    "data_nonmol = [[x[0], int(x[1]), x[2], int(x[3])] for x in data_nonmol]\n",
    "x_nonmol = [x[1] for x in data_nonmol]\n",
    "y_nonmol = [x[3] for x in data_nonmol]\n",
    "\n",
    "# nonoverlap\n",
    "data_nonoverlap = read_file(file_nonoverlap)\n",
    "data_nonoverlap = [[x[0], int(x[1]), x[2], int(x[3])] for x in data_nonoverlap]\n",
    "x_nonoverlap = [x[1] for x in data_nonoverlap]\n",
    "y_nonoverlap = [x[3] for x in data_nonoverlap]\n",
    "\n",
    "\n",
    "# plot histogram of read length divided by mxs count for all datasets\n",
    "data_all = pd.DataFrame(data_all)\n",
    "data_all = data_all.sample(n=10000)\n",
    "x = np.array(data_all[1])\n",
    "y = np.array(data_all[3])\n",
    "y = y/x\n",
    "plt.hist(y, bins=500, alpha=0.8, label='all', color='r')\n",
    "plt.xlabel(\"read length/mxs count\")\n",
    "plt.ylabel(\"Number of reads\")\n",
    "plt.title(\"read length/mxs count\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlim(0, 100)\n",
    "#plt.ylim(0, 2000)\n",
    "plt.axvline(x=20, color='r', linestyle='--')\n",
    "plt.axvline(x=30, color='r', linestyle='--')\n",
    "plt.axvline(x=40, color='r', linestyle='--')\n",
    "plt.axvline(x=50, color='r', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "# other data\n",
    "# nonoverlap\n",
    "data_nonoverlap = pd.DataFrame(data_nonoverlap)\n",
    "data_nonoverlap = data_nonoverlap.sample(n=10000)\n",
    "x = np.array(data_nonoverlap[1])\n",
    "y = np.array(data_nonoverlap[3])\n",
    "y = y/x\n",
    "plt.hist(y, bins=100, alpha=0.8, label='nonoverlap', color='orange')\n",
    "plt.xlabel(\"read length/mxs count\")\n",
    "plt.ylabel(\"Number of reads\")\n",
    "plt.title(\"read length/mxs count\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlim(0, 100)\n",
    "#plt.ylim(0, 2000)\n",
    "# add vertical lines at x=20 and x=30 and x=40 and x=50\n",
    "plt.axvline(x=20, color='r', linestyle='--')\n",
    "plt.axvline(x=30, color='r', linestyle='--')\n",
    "plt.axvline(x=40, color='r', linestyle='--')\n",
    "plt.axvline(x=50, color='r', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "# nonmol\n",
    "data_nonmol = pd.DataFrame(data_nonmol)\n",
    "data_nonmol = data_nonmol.sample(n=10000)\n",
    "x = np.array(data_nonmol[1])\n",
    "y = np.array(data_nonmol[3])\n",
    "y = y/x\n",
    "plt.hist(y, bins=500, alpha=0.8, label='nonmol', color='b')\n",
    "plt.xlabel(\"read length/mxs count\")\n",
    "plt.ylabel(\"Number of reads\")\n",
    "plt.title(\"read length/mxs count\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlim(0, 100)\n",
    "#plt.ylim(0, 2000)\n",
    "plt.axvline(x=20, color='r', linestyle='--')\n",
    "plt.axvline(x=30, color='r', linestyle='--')\n",
    "plt.axvline(x=40, color='r', linestyle='--')\n",
    "plt.axvline(x=50, color='r', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# nonmulti\n",
    "data_nonmulti = pd.DataFrame(data_nonmulti)\n",
    "data_nonmulti = data_nonmulti.sample(n=10000)\n",
    "x = np.array(data_nonmulti[1])\n",
    "y = np.array(data_nonmulti[3])\n",
    "y = y/x\n",
    "plt.hist(y, bins=100, alpha=0.8, label='nonmulti', color='g')\n",
    "plt.xlabel(\"read length/mxs count\")\n",
    "plt.ylabel(\"Number of reads\")\n",
    "plt.title(\"read length/mxs count\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlim(0, 100)\n",
    "#plt.ylim(0, 2000)\n",
    "plt.axvline(x=20, color='r', linestyle='--')\n",
    "plt.axvline(x=30, color='r', linestyle='--')\n",
    "plt.axvline(x=40, color='r', linestyle='--')\n",
    "plt.axvline(x=50, color='r', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "# multi\n",
    "data_multi = pd.DataFrame(data_multi)\n",
    "data_multi = data_multi.sample(n=10000)\n",
    "x = np.array(data_multi[1])\n",
    "y = np.array(data_multi[3])\n",
    "y = y/x\n",
    "plt.hist(y, bins=100, alpha=0.8, label='multi', color='r')\n",
    "plt.xlabel(\"read length/mxs count\")\n",
    "plt.ylabel(\"Number of reads\")\n",
    "plt.title(\"read length/mxs count\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlim(0, 100)\n",
    "#plt.ylim(0, 2000)\n",
    "plt.axvline(x=20, color='r', linestyle='--')\n",
    "plt.axvline(x=30, color='r', linestyle='--')\n",
    "plt.axvline(x=40, color='r', linestyle='--')\n",
    "plt.axvline(x=50, color='r', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "File \u001b[0;32m/projects/btl/aafshinfard/miniconda3/envs/btl-amir/lib/python3.9/site-packages/matplotlib/__init__.py:107\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook, docstring, rcsetup\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning, sanitize_sequence\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mplDeprecation  \u001b[38;5;66;03m# deprecated\u001b[39;00m\n",
      "File \u001b[0;32m/projects/btl/aafshinfard/miniconda3/envs/btl-amir/lib/python3.9/site-packages/matplotlib/rcsetup.py:24\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, animation, cbook\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n",
      "File \u001b[0;32m/projects/btl/aafshinfard/miniconda3/envs/btl-amir/lib/python3.9/site-packages/matplotlib/animation.py:34\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_animation_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     38\u001b[0m     DISPLAY_TEMPLATE, INCLUDED_FRAMES, JS_INCLUDE, STYLE_INCLUDE)\n",
      "File \u001b[0;32m/projects/btl/aafshinfard/miniconda3/envs/btl-amir/lib/python3.9/site-packages/PIL/Image.py:100\u001b[0m\n\u001b[1;32m     91\u001b[0m MAX_IMAGE_PIXELS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# If the _imaging C module is not present, Pillow will not load.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# Note that other modules should not refer to _imaging directly;\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# import Image and use the Image.core variable instead.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# Also note that Image.core is not a publicly documented interface,\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# and should be considered private and subject to change.\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _imaging \u001b[38;5;28;01mas\u001b[39;00m core\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m __version__ \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(core, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPILLOW_VERSION\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    104\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe _imaging extension was built for another version of Pillow or PIL:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCore version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mgetattr\u001b[39m(core, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPILLOW_VERSION\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPillow version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import for min of two values\n",
    "import operator\n",
    "\n",
    "\n",
    "file_dir=\"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/chm13/physlr_rle/default_indexlr--pos/data/\"\n",
    "file_name = \"CHM13.rle.k40-w32.physlr.flanks.fsize2000.tsv\"\n",
    "\n",
    "\n",
    "\n",
    "file_dir=\"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/hg01243/physlr_rle/default_indexlr--pos/data/\"\n",
    "file_name =\"HG01243.rle.k40-w32.physlr--pos.flanks.fsize2000.tsv\"\n",
    "\n",
    "#/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/hg002gv5/physlr_rle/default_indexlr--pos/data/HG002gv5.rle.k40-w32.physlr--pos.goldend-2000-0.tsv\n",
    "file_dir=\"/projects/btl_scratch/aafshinfard/projects/physlr-goldrush/paper_experiments/hg002gv5/physlr_rle/default_indexlr--pos/data/\"\n",
    "file_name = \"HG002gv5.rle.k40-w32.physlr--pos.goldend-2000-0.tsv\"\n",
    "\n",
    "\n",
    "file=file_dir+file_name\n",
    "\n",
    "\n",
    "# this file has three columns, first is read name, second and third are number of minimizers in the left and right flanks of the read\n",
    "# read the file and plot a histogram of min number of minimizers in the left and right flanks\n",
    "\n",
    "def read_file(file_ad):\n",
    "    with open(file_ad, 'r') as file:\n",
    "        data = file.readlines()\n",
    "    data = [x.split() for x in data]\n",
    "    #data = [x.split() for x in data if len(x) > 100]\n",
    "    return data\n",
    "\n",
    "data = read_file(file)\n",
    "data_int = [[x[0], int(x[1]), int(x[2])] for x in data]\n",
    "\n",
    "# plot histogram of min number of minimizers in the left and right flanks\n",
    "left = [x[1] for x in data_int]\n",
    "right = [x[2] for x in data_int]\n",
    "\n",
    "plt.hist(left, bins=100, alpha=0.8, label='left', color='r')\n",
    "plt.hist(right, bins=100, alpha=0.8, label='right', color='b')\n",
    "plt.xlabel(\"Number of minimizers\")\n",
    "plt.ylabel(\"Number of reads\")\n",
    "plt.title(\"Number of minimizers in left and right flanks\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# for each read, take the minimum of the number of minimizers in the left and right flanks and plot a histogram for all\n",
    "min_flanks = [min(x[1], x[2]) for x in data_int]\n",
    "\n",
    "plt.hist(min_flanks, bins=100, alpha=0.8, label='min_flanks', color='g')\n",
    "plt.xlabel(\"Number of minimizers\")\n",
    "plt.ylabel(\"Number of reads\")\n",
    "plt.title(\"Minimum number of minimizers in left and right flanks\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# print the min, max, mean, median, and std of min_flanks\n",
    "print(\"min of min_flanks: \", min(min_flanks))\n",
    "print(\"max of min_flanks: \", max(min_flanks))\n",
    "print(\"mean of min_flanks: \", np.mean(min_flanks))\n",
    "print(\"median of min_flanks: \", np.median(min_flanks))\n",
    "print(\"std of min_flanks: \", np.std(min_flanks))\n",
    "# print how many are below 200, 250 and 270\n",
    "print(\"below 100: \", len([x for x in min_flanks if x < 100]))\n",
    "print(\"below 105: \", len([x for x in min_flanks if x < 105]))\n",
    "print(\"below 110: \", len([x for x in min_flanks if x < 110]))\n",
    "print(\"below 150: \", len([x for x in min_flanks if x < 150]))\n",
    "print(\"below 170: \", len([x for x in min_flanks if x < 170]))\n",
    "# total number of reads\n",
    "print(\"total number of reads: \", len(min_flanks))\n",
    "\n",
    "# plot absolute difference between left and right flanks\n",
    "diff_flanks = [abs(x[1] - x[2]) for x in data_int]\n",
    "plt.hist(diff_flanks, bins=100, alpha=0.8, label='diff_flanks', color='y')\n",
    "plt.xlabel(\"Absolute difference in number of minimizers\")\n",
    "plt.ylabel(\"Number of reads\")\n",
    "plt.title(\"Absolute difference in number of minimizers in left and right flanks\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plot the cumulative distribution of min_flanks\n",
    "min_flanks = sorted(min_flanks)\n",
    "plt.plot(min_flanks, np.linspace(0, 1, len(min_flanks), endpoint=False))\n",
    "plt.xlabel(\"Number of minimizers\")\n",
    "plt.ylabel(\"cumulative distribution\")\n",
    "plt.title(\"cumulative distribution of minimum number of minimizers in left and right flanks\")\n",
    "# plot a vertical line at x=100 another at x=105 and another at x=110\n",
    "plt.axvline(x=100, color='r', linestyle='--')\n",
    "plt.axvline(x=105, color='r', linestyle='--')\n",
    "plt.axvline(x=110, color='r', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "# print name of reads with minimum number of minimizers in the flanks below 250 in a file with prefix min_flanks_below_250.tsv\n",
    "# find the reads with minimum number of minimizers in the flanks below 250\n",
    "min_flanks_below_100 = [x for x in data_int if min(x[1], x[2]) < 100]\n",
    "min_flanks_below_105 = [x for x in data_int if min(x[1], x[2]) < 105]\n",
    "min_flanks_below_110 = [x for x in data_int if min(x[1], x[2]) < 110]\n",
    "# write the read names to a file, in the same directory\n",
    "\n",
    "# outfile = file_dir + file_name + \"_min_flanks_below_100.tsv\"\n",
    "# with open(outfile, 'w') as file:\n",
    "#     for x in min_flanks_below_100:\n",
    "#         file.write(x[0] + \"\\n\")\n",
    "\n",
    "# outfile = file_dir + file_name + \"_min_flanks_below_105.tsv\"\n",
    "# with open(outfile, 'w') as file:\n",
    "#     for x in min_flanks_below_105:\n",
    "#         file.write(x[0] + \"\\n\")\n",
    "\n",
    "# outfile = file_dir + file_name + \"_min_flanks_below_110.tsv\"\n",
    "# with open(outfile, 'w') as file:\n",
    "#     for x in min_flanks_below_110:\n",
    "#         file.write(x[0] + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# write all read names in data_int to a file\n",
    "# outfile = file_dir + file_name + \"_all-readnames.tsv\"\n",
    "# with open(outfile, 'w') as file:\n",
    "#     for x in data_int:\n",
    "#         file.write(x[0] + \"\\n\")\n",
    "\n",
    "# \n",
    "min_flanks_over_100 = [x for x in data_int if min(x[1], x[2]) >= 100]\n",
    "# print size of min_flanks_over_100\n",
    "# print(\"size of min_flanks_over_100: \", len(min_flanks_over_100))\n",
    "# # print read names of reads with minimum number of minimizers in the flanks over 110 in outfile\n",
    "# outfile = file_dir + file_name + \"_min_flanks_over_100-readnames.tsv\"\n",
    "# with open(outfile, 'w') as file:\n",
    "#     for x in min_flanks_over_100:\n",
    "#         file.write(x[0] + \"\\n\")\n",
    "\n",
    "min_flanks_over_105 = [x for x in data_int if min(x[1], x[2]) >= 105]\n",
    "# print size of min_flanks_over_105\n",
    "# print(\"size of min_flanks_over_105: \", len(min_flanks_over_105))\n",
    "# # print read names of reads with minimum number of minimizers in the flanks over 105 in outfile\n",
    "# outfile = file_dir + file_name + \"_min_flanks_over_105-readnames.tsv\"\n",
    "# with open(outfile, 'w') as file:\n",
    "#     for x in min_flanks_over_105:\n",
    "#         file.write(x[0] + \"\\n\")\n",
    "\n",
    "print(\"FINISHED\")\n",
    "\n",
    "# min_flanks_over_110 = [x for x in data_int if min(x[1], x[2]) >= 110]\n",
    "# # print size of min_flanks_over_110\n",
    "# print(\"size of min_flanks_over_110: \", len(min_flanks_over_110))\n",
    "# # print read names of reads with minimum number of minimizers in the flanks over 110 in outfile\n",
    "# outfile = file_dir + file_name + \"_min_flanks_over_110-readnames.tsv\"\n",
    "# with open(outfile, 'w') as file:\n",
    "#     for x in min_flanks_over_110:\n",
    "#         file.write(x[0] + \"\\n\")\n",
    "\n",
    "# outfile = file_dir + file_name + \"_min_flanks_below_270.tsv\"\n",
    "# with open(outfile, 'w') as file:\n",
    "#     for x in min_flanks_below_270:\n",
    "#         file.write(x[0] + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "btl-amir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
